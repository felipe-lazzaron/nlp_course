{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content-based search\n",
    "\n",
    "The Internet has brought forward a marvelous source of information. But - simply knowing that we *have* information is just not enough to *use* this information. For example, we *know* that, somewhere on the Internet, there is a book on Natural Language Processing. But, how can we find this book?\n",
    "\n",
    "In this notebook, we are going to work with the following use case (which was also approached in [Amami et al., \"An LDA-Based Approach to Scientific Paper Recommendation\",Natural Language Processing and Information Systems, 2016 ](http://link.springer.com/10.1007/978-3-319-41754-7_17), based on ideas by [Griffiths and Steyvers, \"Finding Scientific Topics\", Proc. Natl. Acad. Sci. U.S.A., 2004](https://doi.org/10.1073/pnas.0307752101).\n",
    "\n",
    "Suppose a scientist is writing an article. Articles usually start with a session called \"abstract\", which summarizes the contents of the whole paper. We want our system to get the abstract we are working with, and then find possible articles we could work with.\n",
    "\n",
    "We will start by simulating our data with a subset of an ArXiv dataset available at Kaggle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import kagglehub\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "    \n",
    "path = kagglehub.dataset_download(\"tiagoft/arvix-data-filtered-for-cs-only-data\")\n",
    "path = Path(path)\n",
    "df = pd.read_csv(path / 'arxiv-metadata-oai-snaptshot-cs-only.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_title = \"Enhancing Autonomous Agents with Multimodal Generative AI for Improved Human-AI Collaboration\"\n",
    "sample_abstract = \"\"\"The integration of multimodal generative AI into autonomous agents presents a significant advancement in human-AI collaboration. \n",
    "This study explores the development of autonomous agents capable of processing and generating various data types,\n",
    "including text-to-image and image-to-audio conversions. By leveraging multimodal generative AI, these agents can interpret and generate \n",
    "content across different modalities, enhancing their ability to interact with humans in more natural and intuitive ways.\n",
    "We propose a novel framework that combines generative AI with transfer learning techniques to enable autonomous agents to adapt \n",
    "knowledge acquired from one context to another with minimal additional data. Our experiments demonstrate that this approach significantly\n",
    "improves the agents' performance in tasks requiring human-AI collaboration, such as virtual reality environments and smart city applications.\n",
    "The results highlight the potential of multimodal generative AI to revolutionize human-AI interaction, paving the way for more immersive \n",
    "and adaptive collaborative experiences.\n",
    "\"\"\"\n",
    "sample_keywords = [\"autonomous agents\", \"multimodal generative AI\", \"human-AI collaboration\", \"transfer learning\", \"virtual reality\", \"smart city applications\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: search by keyword\n",
    "\n",
    "Searching by keywords is somewhat simple because we can simply use an inverted index. In fact, online search engines usually implement inverted index.\n",
    "\n",
    "Use your inverted index to try to find other, relevant articles within our dataset using the keywords provided by the abstract's author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: finding better keywords\n",
    "\n",
    "Keywords are words that differentiate a particular document from the other documents in the collection.\n",
    "\n",
    "This means that the TFIDF measure could be useful to find keywords within a document.\n",
    "\n",
    "For such, fit a TFIDF vectorizer in the whole collection of abstracts and then experiment to find out:\n",
    "\n",
    "1. if the words with largest TFIDF in our abstract are the same as the proposed keywords\n",
    "1. if the words are meaningful towards our abstract\n",
    "1. if searching by the TFIDF-generated words could lead to better recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: modelling abstracts with topics\n",
    "\n",
    "Remember that, in our topic model with LDA, we decompose the word count matrix as:\n",
    "\n",
    "$$\n",
    "X \\approx BA,\n",
    "$$\n",
    "\n",
    "where $B$ contains a representation of each document in terms of its topics.\n",
    "\n",
    "However, we have not discussed how to find an optimal number of topics.\n",
    "\n",
    "The idea used by [Amami et al.](http://link.springer.com/10.1007/978-3-319-41754-7_17) is to choose the number of topics that minimizes a metric called *perplexity*.\n",
    "\n",
    "Perplexity is a measure of the certainty of sampling a word using our model (see [Griffiths and Steyvers](https://doi.org/10.1073/pnas.0307752101)). Lower values are better. With too few topics, the model is in fact making very broad assumptions regarding data; with too many topics, there is a greater chance of finding data is too sparse for a relevant estimation.\n",
    "\n",
    "Modify the code below to find an optimal number of topics for our data. Then, decompose all documents in the collection (also, do it to our abstract!) using the topic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tqdm import tqdm\n",
    "\n",
    "print('Fitting vectorizer')\n",
    "vectorizer = CountVectorizer(stop_words='english', min_df=10, max_df=0.8, max_features=1000).fit(df['abstract'])\n",
    "abstract_vectorized = vectorizer.transform(df['abstract'].sample(10000))\n",
    "\n",
    "print('Fitting LDA')\n",
    "for n_components in tqdm([2, 10, 20, 50, 100]):\n",
    "    lda = LatentDirichletAllocation(n_components=n_components, random_state=42, n_jobs=-1)\n",
    "    lda.fit(abstract_vectorized)\n",
    "    print(f\"Number of components: {n_components}. Perplexity: {lda.perplexity(abstract_vectorized)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: KL and JS divergences\n",
    "\n",
    "The decomposition resulting from LDA is a probability distribution. The distance between two probability distributions can be calculated using the Kullback-Leibner divergence, which is calculated by:\n",
    "\n",
    "$$\n",
    "D_{KL}(P \\parallel Q) = \\sum_{i} P(i) \\log \\left( \\frac{P(i)}{Q(i)} \\right)\n",
    "$$\n",
    "\n",
    "However, the KL divergence is not symetric, which was bothersome to Amani and their colleagues. For this reason, they used the Jensen-Shannon (JS) divergence, given by:\n",
    "\n",
    "$$\n",
    "D_{JS}(P,Q) = \\frac{D_{KL}(P \\parallel Q) + D_{KL}(Q \\parallel P)}{2}\n",
    "$$\n",
    "\n",
    "See the code below demonstrating how this works in practice:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import jensenshannon\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=5, random_state=42, n_jobs=-1)\n",
    "lda.fit(abstract_vectorized)\n",
    "\n",
    "topics1 = lda.transform(abstract_vectorized[0,:])\n",
    "topics2 = lda.transform(abstract_vectorized[1,:])\n",
    "topics3 = lda.transform(abstract_vectorized[500,:])\n",
    "\n",
    "print(topics1)\n",
    "print(topics2)\n",
    "print(topics3)\n",
    "\n",
    "print(jensenshannon(topics1.ravel(), topics2.ravel()))\n",
    "print(jensenshannon(topics1.ravel(), topics3.ravel()))\n",
    "print(jensenshannon(topics2.ravel(), topics3.ravel()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the LDA models you fitted in Exercise 4. Find the topic models for our abstract, and for each of the elements in the dataset. Then, make a function that retrieves the $K$ elements (where $K$ is an integer you can choose!) from the dataset that are closer to our abstract!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "\n",
    "Compare the recommendations provided by keyword searching, by TDIDF keyword searching, and by topic modelling. \n",
    "\n",
    "1. Which recommendation seems more useful?\n",
    "1. Could you combine the techniques above (at least 2 of them) to get a possibly better recommendation?\n",
    "1. Can you use an LLM to help with this task? How? Implement an LLM-based solution and compare it with the previous ones.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
