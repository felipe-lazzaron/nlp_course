{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying texts\n",
    "\n",
    "## The Bag-of-Words model\n",
    "\n",
    "A classifier receives as input a vector of observations, which we will call $x$. This vector describes the content of an item of a dataset. The classifier uses $x$ to estimate a vector $y$ that represents the probability that the corresponding item belongs to each one of the $N$ known classes, that is:\n",
    "\n",
    "$$\n",
    "y = y(x) = \\{P(C=c_n | x)\\} =\\{ P(C=c_1 | x), P(C=c_2 | x), \\cdots, P(C=c_N | x)\\} \n",
    "$$\n",
    "\n",
    "For example: suppose we are trying to classify books into the categories \"romance\" and \"fantasy\". Then, we should somehow estimate a vector $x$ for each book in our collection (or: for each *item* in our *dataset*). After that, we have to find out some way to make a function that estimates $y$. Finally, each item in the dataset will be related to a vector of probabilities $y$. The components of $y$ can be interpreted as probabilities, e.g., $y=[0.2,0.8]$ means that the corresponding item has $20\\%$ probability of being from class 1 (in our case: romance) and $80\\%$ probability of being from class 2 (in our case: fantasy).\n",
    "\n",
    "### Estimating statistics from data\n",
    "\n",
    "The formulation we just saw assumes that $x$ is something we can measure from data. In many cases, measures are precise. For example, we can measure the age of a person without error. However, in most classification problems, our measures have many aspects we cannot account for. For example, it is very likely that mango trees have an expected height, but that expected value will not correspond exactly to any particular mango trees. Instead, we expect to see a distribution around it. It could be reasonable, in this case, to think about a Normal distribution with estimated mean and variances.\n",
    "\n",
    "Likewise, in the case of texts, we should think about what is possible to measure and what is not possible to measure.\n",
    "\n",
    "One thing we *can* measure very precisely is whether a particular text contains a particular word - we have done this several times, already!\n",
    "\n",
    "Also, we can very precisely *count* how many documents in a collection contain a particular word.\n",
    "\n",
    "But, see, our classification problem concerns documents we have never seen before. This is a bit paradoxical: the best way to check if a book is \"romance\" or \"fiction\" is to have a full list of all \"romance\" and \"fiction\" books, and find our book there. However, the classification problem focuses in a situation in which we are looking at a new (never-seen-before) book. Perhaps we just wrote a book and want to know where to sell it? Perhaps we want to know if the book strongly fits one of these genres?\n",
    "\n",
    "Of course, we cannot possibly have a catalogue including books that are yet to be written. So, we should make a model as to how a book in a particular genre behaves. This type of model is called a \"generative\" model (although nowadays the word \"generative\" is being used for other things as well).\n",
    "\n",
    "In a generative model, we assume that there is a probability distribution that generates new books from a particular genre. Hence, a particular book is a *sample* of that distribution. Now, we have to *estimate* the distribution parameters!\n",
    "\n",
    "If we want to estimate the distribution *parameters*, we first have to choose its shape. To make this choice, we should look at:\n",
    "\n",
    "1. The things we can measure\n",
    "1. What models make sense for it\n",
    "\n",
    "For example, we can measure if a particular book contains a particular word. If we assume that books from a genre are written independently, and that the words chosen in each book are independent from each other (these are naive assumptions...), then a book containing a word behaves very similarly to tossing a biased coin.\n",
    "\n",
    "Yes.\n",
    "\n",
    "We are talking about a [Bernoulli distribution](https://en.wikipedia.org/wiki/Bernoulli_distribution) here.\n",
    "\n",
    "The advantage of assuming a Bernoulli distribution is that we can import all the theory underlying it to our problem. Of course, the disadvantage of assuming anything is that we have made some concessions regarding how literature works, in special about the independence aspect. Thus, we will have the problem of finding out how much these assumptions have harmed our model.\n",
    "\n",
    "Before that, we should remember how the Bernoulli distribution works.\n",
    "\n",
    "The Bernoulli distribution describes a process that has two outcomes (typically: heads and tails in a coin toss)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f2f2f2; color: #000;\">\n",
    "\n",
    "\n",
    "Classificando Textos\n",
    "\n",
    "O Modelo Bag-of-Words\n",
    "\n",
    "Um classificador recebe como entrada um vetor de observações, que chamaremos de $x$. Esse vetor descreve o conteúdo de um item de um conjunto de dados. O classificador utiliza $x$ para estimar um vetor $y$ que representa a probabilidade de que o item correspondente pertença a cada uma das $N$ classes conhecidas, isto é:\n",
    "\n",
    "$$\n",
    "y = y(x) = {P(C=c_n | x)} ={ P(C=c_1 | x), P(C=c_2 | x), \\cdots, P(C=c_N | x)}\n",
    "$$\n",
    "\n",
    "Por exemplo: suponha que estamos tentando classificar livros nas categorias “romance” e “fantasia”. Então, devemos de alguma forma estimar um vetor $x$ para cada livro em nossa coleção (ou: para cada item em nosso conjunto de dados). Após isso, precisamos encontrar uma maneira de criar uma função que estime $y$. Por fim, cada item no conjunto de dados estará relacionado a um vetor de probabilidades $y$. Os componentes de $y$ podem ser interpretados como probabilidades, por exemplo, $y=[0.2,0.8]$ significa que o item correspondente tem $20%$ de probabilidade de pertencer à classe 1 (no nosso caso: romance) e $80%$ de probabilidade de pertencer à classe 2 (no nosso caso: fantasia).\n",
    "\n",
    "Estimando Estatísticas a Partir dos Dados\n",
    "\n",
    "A formulação que acabamos de ver assume que $x$ é algo que podemos medir a partir dos dados. Em muitos casos, as medições são precisas. Por exemplo, podemos medir a idade de uma pessoa sem erro. No entanto, na maioria dos problemas de classificação, nossas medições possuem muitos aspectos que não podemos contabilizar. Por exemplo, é muito provável que mangueiras tenham uma altura esperada, mas esse valor esperado não corresponderá exatamente a nenhuma mangueira em particular. Em vez disso, esperamos ver uma distribuição ao redor desse valor. Poderia ser razoável, nesse caso, pensar em uma distribuição Normal com média e variâncias estimadas.\n",
    "\n",
    "Da mesma forma, no caso dos textos, devemos pensar sobre o que é possível medir e o que não é possível medir.\n",
    "\n",
    "Uma coisa que podemos medir com muita precisão é se um determinado texto contém uma determinada palavra — já fizemos isso várias vezes!\n",
    "\n",
    "Além disso, podemos contar com muita precisão quantos documentos em um conjunto contêm uma determinada palavra.\n",
    "\n",
    "Mas, veja, nosso problema de classificação diz respeito a documentos que nunca vimos antes. Isso é um pouco paradoxal: a melhor maneira de verificar se um livro é “romance” ou “ficção” é ter uma lista completa de todos os livros “romance” e “ficção” e encontrar o nosso livro nela. No entanto, o problema de classificação foca em uma situação na qual estamos analisando um livro novo (nunca visto antes). Talvez tenhamos acabado de escrever um livro e queiramos saber onde vendê-lo? Talvez desejemos saber se o livro se encaixa fortemente em um desses gêneros?\n",
    "\n",
    "Claro que não podemos ter, de forma alguma, um catálogo que inclua livros que ainda serão escritos. Portanto, devemos criar um modelo de como um livro em um determinado gênero se comporta. Esse tipo de modelo é chamado de modelo “generativo” (embora, atualmente, a palavra “generativo” esteja sendo utilizada para outras coisas também).\n",
    "\n",
    "Em um modelo generativo, assumimos que existe uma distribuição de probabilidade que gera novos livros a partir de um determinado gênero. Assim, um livro em particular é uma amostra dessa distribuição. Agora, precisamos estimar os parâmetros da distribuição!\n",
    "\n",
    "Se quisermos estimar os parâmetros da distribuição, primeiro precisamos escolher sua forma. Para fazer essa escolha, devemos considerar:\n",
    "\t1.\tAs coisas que podemos medir\n",
    "\t2.\tQuais modelos fazem sentido para isso\n",
    "\n",
    "Por exemplo, podemos medir se um determinado livro contém uma determinada palavra. Se assumirmos que os livros de um gênero são escritos de forma independente e que as palavras escolhidas em cada livro são independentes entre si (essas são suposições ingênuas…), então um livro que contém uma palavra se comporta de maneira muito semelhante a lançar uma moeda viciada.\n",
    "\n",
    "Sim.\n",
    "\n",
    "Estamos falando de uma distribuição de Bernoulli aqui.\n",
    "\n",
    "A vantagem de assumir uma distribuição de Bernoulli é que podemos importar toda a teoria subjacente a ela para o nosso problema. Claro, a desvantagem de assumir qualquer modelo é que fazemos algumas concessões em relação a como a literatura funciona, especialmente no que diz respeito ao aspecto de independência. Assim, teremos o problema de descobrir o quanto essas suposições prejudicaram nosso modelo.\n",
    "\n",
    "Antes disso, devemos lembrar como funciona a distribuição de Bernoulli.\n",
    "\n",
    "A distribuição de Bernoulli descreve um processo que possui dois resultados (tipicamente: cara e coroa em um lançamento de moeda).\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "Which of the phenomena below could be modelled using a Bernoulli distribution?\n",
    "\n",
    "1. Flipping a coin and recording whether it lands on heads (1) or tails (0).\n",
    "1. Rolling a die and recording whether the result is a 4. \n",
    "1. Measuring the height of students in a classroom. \n",
    "1. Determining whether a light bulb is functional or not (on or off). \n",
    "1. Surveying whether a person votes in an election (yes or no). \n",
    "    the number of cars passing through an intersection in one hour. \n",
    "1. Determining if a customer makes a purchase or not.  \n",
    "1. Measuring the temperature outside every hour. \n",
    "1. Checking whether a software test passes or fails. \n",
    "1. Checking how if a book contains the word \"dragon\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` \n",
    "Enunciado:\n",
    "O exercício pede identificar quais dos fenômenos listados podem ser modelados usando uma distribuição de Bernoulli, isto é, processos que resultam em apenas dois possíveis resultados (por exemplo, sucesso/fracasso, sim/não).\n",
    "\n",
    "Contextualização:\n",
    "Na aula, vimos que a distribuição de Bernoulli é apropriada para modelar eventos binários. Essa distribuição descreve experimentos com apenas dois resultados possíveis, onde geralmente representamos o resultado de sucesso como 1 e o de fracasso como 0. Exemplos clássicos incluem o lançamento de uma moeda (cara ou coroa) ou a verificação da presença/ausência de uma palavra em um texto.\n",
    "\n",
    "Resolução Detalhada:\n",
    "\t1.\tLançar uma moeda e registrar se caiu cara (1) ou coroa (0).\n",
    "\t•\tAnálise: É o exemplo clássico de um experimento Bernoulli.\n",
    "\t•\tConclusão: Pode ser modelado com uma distribuição de Bernoulli.\n",
    "\t2.\tLançar um dado e registrar se o resultado é 4.\n",
    "\t•\tAnálise: Apesar de um dado ter seis faces, definindo “sucesso” como sair 4 e “fracasso” como sair qualquer outro número, o experimento se torna binário (4 ou não 4).\n",
    "\t•\tConclusão: Pode ser modelado com uma distribuição de Bernoulli.\n",
    "\t3.\tMedir a altura dos alunos em uma sala de aula.\n",
    "\t•\tAnálise: A altura é uma variável contínua, não se restringindo a dois possíveis resultados.\n",
    "\t•\tConclusão: Não pode ser modelado com uma distribuição de Bernoulli.\n",
    "\t4.\tDeterminar se uma lâmpada está funcional ou não (ligada ou desligada).\n",
    "\t•\tAnálise: Trata-se de um evento binário: funcional (sim) ou não funcional (não).\n",
    "\t•\tConclusão: Pode ser modelado com uma distribuição de Bernoulli.\n",
    "\t5.\tPesquisar se uma pessoa vota em uma eleição (sim ou não).\n",
    "\t•\tAnálise: É uma resposta binária, com apenas duas possibilidades.\n",
    "\t•\tConclusão: Pode ser modelado com uma distribuição de Bernoulli.\n",
    "\t6.\tContar o número de carros que passam por um cruzamento em uma hora.\n",
    "\t•\tAnálise: Essa variável é uma contagem, que pode ser modelada por distribuições de contagem, como a Poisson, e não é binária.\n",
    "\t•\tConclusão: Não pode ser modelado com uma distribuição de Bernoulli.\n",
    "\t7.\tDeterminar se um cliente realiza uma compra ou não.\n",
    "\t•\tAnálise: O evento é binário: o cliente compra (sim) ou não compra (não).\n",
    "\t•\tConclusão: Pode ser modelado com uma distribuição de Bernoulli.\n",
    "\t8.\tMedir a temperatura externa a cada hora.\n",
    "\t•\tAnálise: A temperatura é uma variável contínua, não limitada a dois resultados.\n",
    "\t•\tConclusão: Não pode ser modelado com uma distribuição de Bernoulli.\n",
    "\t9.\tVerificar se um teste de software passa ou falha.\n",
    "\t•\tAnálise: Trata-se de um evento binário: o teste passa (sucesso) ou falha (fracasso).\n",
    "\t•\tConclusão: Pode ser modelado com uma distribuição de Bernoulli.\n",
    "\t10.\tVerificar se um livro contém a palavra “dragon”.\n",
    "\t•\tAnálise: Esse fenômeno tem resultado binário: o livro contém (sim) ou não contém (não) a palavra.\n",
    "\t•\tConclusão: Pode ser modelado com uma distribuição de Bernoulli.\n",
    "\n",
    "Conclusão Objetiva:\n",
    "Os fenômenos que podem ser modelados usando uma distribuição de Bernoulli são os itens 1, 2, 4, 5, 7, 9 e 10. Os itens 3, 6 e 8 não são adequados para esse modelo.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: reviewsing the Bayes rule\n",
    "\n",
    "The Bayes Rule, or the Bayes Theorem, regards the idea of inverting conditionals. A conditional probability is a probability calculated under the assumption of something being known. We write it as $P(A|B)$, which is read: \"probability of $A$ given $B$\". In real life, we live situations like that all the time. For example, there is a probability that any day, picked at random, is rainy. However, if we pick any day in which we know everyone is using umbrellas, then the probability of picking a rainy day is different, that is, $P(\\text{rain}) \\neq P(\\text{rain} | \\text{everyone is using umbrellas})$.\n",
    "  \n",
    "We can use the diagram above to calculate the probability of $A$ given $B$. In this case, we need to compute all favorable and possible events (which is $A \\cap B$, because we *know* $B$ happens) and divide by all possible events (which is $B$, as we *know* $B$ happens). Hence, the conditional can be written as:\n",
    "\n",
    "$$\n",
    "P(A | B) = \\frac{P(A \\cap B)}{P(B)}\n",
    "$$\n",
    "\n",
    "We can use a similar reasoning to find that:\n",
    "\n",
    "$$\n",
    "P(B | A) = \\frac{P(B \\cap A)}{P(A)}\n",
    "$$\n",
    "\n",
    "Since $A \\cap B = B \\cap A$, we can rewrite the equations above as:\n",
    "\n",
    "$$\n",
    "P(A|B)P(B) = P(A \\cap B) =  P(B|A)P(A) \n",
    "$$\n",
    "\n",
    "This is the Bayes rule.\n",
    "\n",
    "**Question**\n",
    "\n",
    "If $P(A) = 0.5$, $P(B) = 0.25$, $P(A \\cap B)=0.1$, what is $P(A|B)$? What is $P(B|A)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício sobre Probabilidades Condicionais\n",
    "\n",
    "---\n",
    "\n",
    "### Enunciado\n",
    "\n",
    "Calcule as probabilidades condicionais \\( P(A|B) \\) e \\( P(B|A) \\).\n",
    "\n",
    "### Informações fornecidas:\n",
    "\n",
    "- \\( P(A) = 0,5 \\)\n",
    "- \\( P(B) = 0,25 \\)\n",
    "- \\( P(A \\cap B) = 0,1 \\)\n",
    "\n",
    "---\n",
    "\n",
    "### Fundamento teórico:\n",
    "\n",
    "A probabilidade condicional é calculada pelas fórmulas:\n",
    "\n",
    "\\[\n",
    "P(A|B) = \\frac{P(A \\cap B)}{P(B)}\n",
    "\\]\n",
    "\n",
    "\\[\n",
    "P(B|A) = \\frac{P(A \\cap B)}{P(A)}\n",
    "\\]\n",
    "\n",
    "Essas fórmulas nos permitem avaliar a probabilidade de ocorrência de um evento sabendo que outro evento já ocorreu.\n",
    "\n",
    "---\n",
    "\n",
    "### Resolução passo a passo:\n",
    "\n",
    "**1. Probabilidade de A dado B:**\n",
    "\n",
    "\\[\n",
    "P(A|B) = \\frac{P(A \\cap B)}{P(B)} = \\frac{0,1}{0,25} = 0,4\n",
    "\\]\n",
    "\n",
    "_Interpretação:_  \n",
    "Dado que o evento B ocorreu, a probabilidade de ocorrer o evento A é **40%**.\n",
    "\n",
    "**2. Probabilidade de B dado A:**\n",
    "\n",
    "\\[\n",
    "P(B|A) = \\frac{P(A \\cap B)}{P(A)} = \\frac{0,1}{0,5} = 0,2\n",
    "\\]\n",
    "\n",
    "_Interpretação:_  \n",
    "Dado que o evento A ocorreu, a probabilidade de B ocorrer é 20%.\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusão objetiva:\n",
    "\n",
    "As probabilidades condicionais encontradas são:\n",
    "\n",
    "- \\( P(A|B) = 0,4 \\) ou 40%\n",
    "- \\( P(B|A) = 0,2 \\)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: applying the Bayes rule\n",
    "\n",
    "We are going to use the Bayes rule to estimate a likelihood of a document being from a particular class -- or, in our example, of a movie being of a particular genre -- given that it contains a word we choose. Let's start with the word \"funny\". \n",
    "\n",
    "As I write this text, I wonder that comedy and drama plots probably have different probabilities of having the word \"funny\", hence:\n",
    "\n",
    "$$\n",
    "P(\\text{funny} | \\text{comedy}) \\neq P(\\text{funny} | \\text{drama})\n",
    "$$\n",
    "\n",
    "The good news about the probabilities above is that we can estimate them by counting, like we did in the Models section. For such, we get all the plots each genre and estimate the probability of using the word \"funny\":\n",
    " \n",
    "\n",
    " \n",
    "def has_word(word, text):\n",
    "    import re\n",
    "    tokens = re.findall(r'\\w+', text.lower())\n",
    "    ret = word.lower() in tokens\n",
    "    return ret\n",
    "\n",
    "def P_word_given_genre(word, genre):\n",
    "    if genre is not None:\n",
    "        genre_df = df[df['Genre'] == genre]\n",
    "    else:\n",
    "        genre_df = df\n",
    "    genre_has_word = genre_df['Plot'].apply(lambda x: has_word(word, x)).astype(int)\n",
    "    ret  =genre_has_word.mean()\n",
    "    return ret\n",
    "\n",
    "word = \"funny\"\n",
    "P_word_given_drama = P_word_given_genre(word, 'drama')\n",
    "P_word_given_comedy = P_word_given_genre(word, 'comedy')\n",
    "\n",
    "print(P_word_given_comedy, P_word_given_drama)\n",
    " \n",
    "\n",
    " \n",
    "The quantities we calculated are $P(\\text{funny} | \\text{comedy})$ and $P(\\text{funny} | \\text{drama})$. However, we are interested in estimated the probability of a plot belonging to a genre given that we *know* that they contain (or not) that particular word. We can *know* that because we can precisely measure it from data, whereas we cannot measure the \"genre\" of a plot from data.\n",
    "\n",
    "We can use Bayes' rule and state that:\n",
    "\n",
    "$$\n",
    "P(\\text{comedy} | \\text{funny} ) = \\frac{P(\\text{funny} | \\text{comedy}) P(\\text{comedy})}{P(\\text{funny})}\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "* $P(\\text{funny})$ is the probability that the word \"funny\" appears in a random text from the collection, and\n",
    "* $P(\\text{comedy})$ is the probability that a random text from the collection is of the comedy genre.\n",
    "    \n",
    "Using the data found [here](https://raw.githubusercontent.com/tiagoft/NLP/main/wiki_movie_plots_drama_comedy.csv), estimate the probabilities below:\n",
    "\n",
    "1. $P(\\text{comedy})$\n",
    "1. $P(\\text{drama})$\n",
    "1. $P(\\text{funny})$\n",
    "1. $P(\\text{comedy} | \\text{funny})$\n",
    "1. $P(\\text{drama} | \\text{funny})$\n",
    "1. $P(\\text{comedy} | \\overline{\\text{funny}})$ (that is, probability of genre being comedy given that the word \"funny\" is *not* in the text)\n",
    "1. $P(\\text{drama} | \\overline{\\text{funny}})$ (that is, probability of genre being drama given that the word \"funny\" is *not* in the text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/tiagoft/NLP/main/wiki_movie_plots_drama_comedy.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\tResolução Detalhada:\n",
    "\t\t1.\tCarregando os Dados:\n",
    "\tUtilizamos o pandas para ler o arquivo CSV contendo os enredos dos filmes e seus gêneros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/tiagoft/NLP/main/wiki_movie_plots_drama_comedy.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\t2.\tCálculo das Probabilidades dos Gêneros (P(\\text{comedy}) e P(\\text{drama})):\n",
    "\t•\tContamos quantos filmes são de cada gênero e dividimos pelo total de filmes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(df)\n",
    "comedy_count = len(df[df['Genre'] == 'comedy'])\n",
    "drama_count = len(df[df['Genre'] == 'drama'])\n",
    "\n",
    "P_comedy = comedy_count / total\n",
    "P_drama = drama_count / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3.\tIdentificando a Presença da Palavra “funny”:\n",
    "    Definimos uma função que tokeniza o texto e verifica se a palavra “funny” aparece."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def has_word(word, text):\n",
    "    tokens = re.findall(r'\\w+', text.lower())\n",
    "    return word.lower() in tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Em seguida, aplicamos essa função em cada enredo para criar uma coluna que indica se “funny” está presente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['contains_funny'] = df['Plot'].apply(lambda x: has_word(\"funny\", x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    4.\tCálculo de P(\\text{funny}):\n",
    "    Dividimos o número de enredos que contêm a palavra “funny” pelo total de enredos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "funny_count = df['contains_funny'].sum()\n",
    "P_funny = funny_count / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \t5.\tCálculo das Probabilidades Condicionais para Textos que Contêm “funny”:\n",
    "Separamos os enredos que contêm “funny” e, dentre esses, contamos quantos são de cada gênero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_funny = df[df['contains_funny'] == True]\n",
    "comedy_funny = len(df_funny[df_funny['Genre'] == 'comedy'])\n",
    "drama_funny = len(df_funny[df_funny['Genre'] == 'drama'])\n",
    "\n",
    "P_comedy_given_funny = comedy_funny / len(df_funny)\n",
    "P_drama_given_funny = drama_funny / len(df_funny)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \t6.\tCálculo das Probabilidades Condicionais para Textos que NÃO Contêm “funny”:\n",
    "Analogamente, separamos os enredos que não contêm “funny” e calculamos as probabilidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_not_funny = df[df['contains_funny'] == False]\n",
    "comedy_not_funny = len(df_not_funny[df_not_funny['Genre'] == 'comedy'])\n",
    "drama_not_funny = len(df_not_funny[df_not_funny['Genre'] == 'drama'])\n",
    "\n",
    "P_comedy_given_not_funny = comedy_not_funny / len(df_not_funny)\n",
    "P_drama_given_not_funny = drama_not_funny / len(df_not_funny)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \t7.\tImplementação Completa e Impressão dos Resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(comedy) = 0.4233781301363241\n",
      "P(drama) = 0.5766218698636759\n",
      "P(funny) = 0.004544136130716426\n",
      "P(comedy|funny) = 0.6595744680851063\n",
      "P(drama|funny) = 0.3404255319148936\n",
      "P(comedy|not funny) = 0.4222999222999223\n",
      "P(drama|not funny) = 0.5777000777000777\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Carregando os dados\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/tiagoft/NLP/main/wiki_movie_plots_drama_comedy.csv')\n",
    "total = len(df)\n",
    "\n",
    "# Probabilidades dos gêneros\n",
    "comedy_count = len(df[df['Genre'] == 'comedy'])\n",
    "drama_count = len(df[df['Genre'] == 'drama'])\n",
    "P_comedy = comedy_count / total\n",
    "P_drama = drama_count / total\n",
    "\n",
    "# Função para identificar a palavra \"funny\"\n",
    "def has_word(word, text):\n",
    "    tokens = re.findall(r'\\w+', text.lower())\n",
    "    return word.lower() in tokens\n",
    "\n",
    "# Coluna indicando se o enredo contém \"funny\"\n",
    "df['contains_funny'] = df['Plot'].apply(lambda x: has_word(\"funny\", x))\n",
    "\n",
    "# Probabilidade de conter \"funny\"\n",
    "funny_count = df['contains_funny'].sum()\n",
    "P_funny = funny_count / total\n",
    "\n",
    "# Probabilidades condicionais para enredos que contêm \"funny\"\n",
    "df_funny = df[df['contains_funny'] == True]\n",
    "comedy_funny = len(df_funny[df_funny['Genre'] == 'comedy'])\n",
    "drama_funny = len(df_funny[df_funny['Genre'] == 'drama'])\n",
    "P_comedy_given_funny = comedy_funny / len(df_funny)\n",
    "P_drama_given_funny = drama_funny / len(df_funny)\n",
    "\n",
    "# Probabilidades condicionais para enredos que NÃO contêm \"funny\"\n",
    "df_not_funny = df[df['contains_funny'] == False]\n",
    "comedy_not_funny = len(df_not_funny[df_not_funny['Genre'] == 'comedy'])\n",
    "drama_not_funny = len(df_not_funny[df_not_funny['Genre'] == 'drama'])\n",
    "P_comedy_given_not_funny = comedy_not_funny / len(df_not_funny)\n",
    "P_drama_given_not_funny = drama_not_funny / len(df_not_funny)\n",
    "\n",
    "print(\"P(comedy) =\", P_comedy)\n",
    "print(\"P(drama) =\", P_drama)\n",
    "print(\"P(funny) =\", P_funny)\n",
    "print(\"P(comedy|funny) =\", P_comedy_given_funny)\n",
    "print(\"P(drama|funny) =\", P_drama_given_funny)\n",
    "print(\"P(comedy|not funny) =\", P_comedy_given_not_funny)\n",
    "print(\"P(drama|not funny) =\", P_drama_given_not_funny)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: the Naive Bayes approach\n",
    "\n",
    "To deal with many words, we are going to *naively* assume that the presence or absense of each word is independent of each other. This is naive because obviously texts that refer to \"dragons\" are more likely to refer to \"sorcerers\", and so on. However, the assumption of independence is interesting because, if many processess are independent, then:\n",
    "\n",
    "$$\n",
    "P(A_1, A_2, \\cdots, A_n) = P(A_1)P(A_2) \\cdots P(A_n)\n",
    "$$\n",
    "\n",
    "We can apply this to the conditional case, with many words $w_1 \\cdots w_n$ and a class $C$:\n",
    "\n",
    "$$\n",
    "P(w_1, w_2, \\cdots, w_n | C ) = P(w_1 | C)P(w_2 | C) \\cdots P(w_n|C)\n",
    "$$\n",
    "\n",
    "Using the Bayes rule, we have that:\n",
    "\n",
    "$$\n",
    "P(C | w_1, w_2, \\cdots, w_n) = \\frac{P(w_1, w_2, \\cdots, w_n | C ) P(C)}{P(w_1, w_2, \\cdots, w_n )}\n",
    "$$\n",
    "\n",
    "Hence:\n",
    "\n",
    "$$\n",
    "P(C | w_1, w_2, \\cdots, w_n) = \\frac{(P(w_1 | C)P(w_2 | C) \\cdots P(w_n|C)) P(C)}{P(w_1) P(w_2) \\cdots P(w_n)}\n",
    "$$\n",
    "\n",
    "We can estimate $P(w_i | C)$ and $P(w_i)$ for each word in the dataset following the same ideas as before.\n",
    "\n",
    "Using the data found [here](https://raw.githubusercontent.com/tiagoft/NLP/main/wiki_movie_plots_drama_comedy.csv), estimate the probabilities below. First, use the exact estimation method. Then, do the same with the naive Bayes assumption.\n",
    "\n",
    "1. $P(\\text{comedy} | \\text{funny}, \\text{sad})$\n",
    "1. $P(\\text{comedy} | \\overline{\\text{funny}}, \\text{sad})$\n",
    "1. $P(\\text{comedy} | \\text{funny}, \\overline{\\text{sad}})$\n",
    "1. $P(\\text{comedy} | \\overline{\\text{funny}}, \\overline{\\text{sad}})$\n",
    "1. $P(\\text{drama} | \\text{funny}, \\text{sad})$\n",
    "1. $P(\\text{drama} | \\overline{\\text{funny}}, \\text{sad})$\n",
    "1. $P(\\text{drama} | \\text{funny}, \\overline{\\text{sad}})$\n",
    "1. $P(\\text{drama} | \\overline{\\text{funny}}, \\overline{\\text{sad}})$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\t1.\tPreparação dos Dados:\n",
    "Carregamos o dataset e criamos duas colunas indicando se o enredo contém “funny” e “sad”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Carrega o dataset\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/tiagoft/NLP/main/wiki_movie_plots_drama_comedy.csv')\n",
    "\n",
    "# Função para detectar a presença de uma palavra\n",
    "def has_word(word, text):\n",
    "    tokens = re.findall(r'\\w+', text.lower())\n",
    "    return word.lower() in tokens\n",
    "\n",
    "# Criação das colunas para \"funny\" e \"sad\"\n",
    "df['contains_funny'] = df['Plot'].apply(lambda x: has_word(\"funny\", x))\n",
    "df['contains_sad'] = df['Plot'].apply(lambda x: has_word(\"sad\", x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2.\tCálculo das Probabilidades Básicas:\n",
    "\t•\tProbabilidades dos gêneros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(df)\n",
    "comedy_count = len(df[df['Genre'] == 'comedy'])\n",
    "drama_count = len(df[df['Genre'] == 'drama'])\n",
    "\n",
    "P_comedy = comedy_count / total\n",
    "P_drama = drama_count / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \t•\tProbabilidades marginais das palavras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_funny = df['contains_funny'].mean()\n",
    "P_sad   = df['contains_sad'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \t3.\t(a) Estimação Exata:\n",
    "\tPara cada combinação, filtramos o dataset e usamos a razão:\n",
    "\t\tP(\\text{genre} | \\text{combinação}) = \\frac{\\text{número de enredos do gênero com a combinação}}{\\text{número total de enredos com a combinação}}\n",
    "\tPor exemplo, para P(\\text{comedy} | \\text{funny}, \\text{sad}):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtra enredos que contêm \"funny\" e \"sad\"\n",
    "df_funny_sad = df[(df['contains_funny'] == True) & (df['contains_sad'] == True)]\n",
    "P_comedy_given_funny_sad_exact = len(df_funny_sad[df_funny_sad['Genre'] == 'comedy']) / len(df_funny_sad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\t4.\t(b) Estimação via Naive Bayes:\n",
    "Aqui, primeiro estimamos as probabilidades condicionais individuais:\n",
    "\t•\tPara a classe comedy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comedy = df[df['Genre'] == 'comedy']\n",
    "P_funny_given_comedy = df_comedy['contains_funny'].mean()\n",
    "P_sad_given_comedy   = df_comedy['contains_sad'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \t•\tPara a classe drama:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drama = df[df['Genre'] == 'drama']\n",
    "P_funny_given_drama = df_drama['contains_funny'].mean()\n",
    "P_sad_given_drama   = df_drama['contains_sad'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\t5.\tExemplo de Implementação Completa e Impressão dos Resultados:\n",
    "Abaixo um exemplo de código que calcula ambos os conjuntos de probabilidades:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(comedy | funny, sad) = 0.5\n",
      "P(comedy | not funny, sad) = 0.3380281690140845\n",
      "P(comedy | funny, not sad) = 0.6666666666666666\n",
      "P(comedy | not funny, not sad) = 0.4228850855745721\n",
      "P(drama | funny, sad) = 0.5\n",
      "P(drama | not funny, sad) = 0.6619718309859155\n",
      "P(drama | funny, not sad) = 0.3333333333333333\n",
      "P(drama | not funny, not sad) = 0.5771149144254278\n",
      "P(comedy | funny, sad) = 0.5335222843931542\n",
      "P(comedy | not funny, sad) = 0.34159360337070266\n",
      "P(comedy | funny, not sad) = 0.660470457316802\n",
      "P(comedy | not funny, not sad) = 0.4228735894159723\n",
      "P(drama | funny, sad) = 0.38819451245508624\n",
      "P(drama | not funny, sad) = 0.6587637500236381\n",
      "P(drama | funny, not sad) = 0.34008598609411134\n",
      "P(drama | not funny, not sad) = 0.5771238704868722\n"
     ]
    }
   ],
   "source": [
    "# Função para calcular a probabilidade condicional exata para uma dada combinação\n",
    "def exact_prob(genre, funny, sad):\n",
    "    subset = df[(df['contains_funny'] == funny) & (df['contains_sad'] == sad)]\n",
    "    if len(subset) == 0:\n",
    "        return None  # Evita divisão por zero\n",
    "    return len(subset[subset['Genre'] == genre]) / len(subset)\n",
    "\n",
    "exact_results = {\n",
    "    'P(comedy | funny, sad)'        : exact_prob('comedy', True, True),\n",
    "    'P(comedy | not funny, sad)'     : exact_prob('comedy', False, True),\n",
    "    'P(comedy | funny, not sad)'     : exact_prob('comedy', True, False),\n",
    "    'P(comedy | not funny, not sad)' : exact_prob('comedy', False, False),\n",
    "    'P(drama | funny, sad)'          : exact_prob('drama', True, True),\n",
    "    'P(drama | not funny, sad)'      : exact_prob('drama', False, True),\n",
    "    'P(drama | funny, not sad)'      : exact_prob('drama', True, False),\n",
    "    'P(drama | not funny, not sad)'  : exact_prob('drama', False, False)\n",
    "}\n",
    "\n",
    "for label, value in exact_results.items():\n",
    "    print(label, \"=\", value)\n",
    "\n",
    "# Probabilidades condicionais individuais para Naive Bayes\n",
    "P_funny_given_comedy = df_comedy['contains_funny'].mean()\n",
    "P_sad_given_comedy   = df_comedy['contains_sad'].mean()\n",
    "P_funny_given_drama  = df_drama['contains_funny'].mean()\n",
    "P_sad_given_drama    = df_drama['contains_sad'].mean()\n",
    "\n",
    "# Função para calcular a probabilidade via Naive Bayes\n",
    "def naive_bayes_prob(genre, funny, sad):\n",
    "    if genre == 'comedy':\n",
    "        prior = P_comedy\n",
    "        likelihood_funny = P_funny_given_comedy if funny else (1 - P_funny_given_comedy)\n",
    "        likelihood_sad   = P_sad_given_comedy   if sad   else (1 - P_sad_given_comedy)\n",
    "    else:\n",
    "        prior = P_drama\n",
    "        likelihood_funny = P_funny_given_drama if funny else (1 - P_funny_given_drama)\n",
    "        likelihood_sad   = P_sad_given_drama   if sad   else (1 - P_sad_given_drama)\n",
    "    \n",
    "    # Probabilidade da evidência (usando as marginais)\n",
    "    evidence = (P_funny if funny else (1 - P_funny)) * (P_sad if sad else (1 - P_sad))\n",
    "    return (likelihood_funny * likelihood_sad * prior) / evidence\n",
    "\n",
    "naive_results = {\n",
    "    'P(comedy | funny, sad)'        : naive_bayes_prob('comedy', True, True),\n",
    "    'P(comedy | not funny, sad)'     : naive_bayes_prob('comedy', False, True),\n",
    "    'P(comedy | funny, not sad)'     : naive_bayes_prob('comedy', True, False),\n",
    "    'P(comedy | not funny, not sad)' : naive_bayes_prob('comedy', False, False),\n",
    "    'P(drama | funny, sad)'          : naive_bayes_prob('drama', True, True),\n",
    "    'P(drama | not funny, sad)'      : naive_bayes_prob('drama', False, True),\n",
    "    'P(drama | funny, not sad)'      : naive_bayes_prob('drama', True, False),\n",
    "    'P(drama | not funny, not sad)'  : naive_bayes_prob('drama', False, False)\n",
    "}\n",
    "\n",
    "for label, value in naive_results.items():\n",
    "    print(label, \"=\", value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: using sklearn\n",
    "\n",
    "# Implementation with Sklearn\n",
    "\n",
    "It is obvious that we are not going to code Naive Bayes from scratch every time. Instead, let's use `sklearn` and its potential to help us. Let's check an example code:\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.74\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Plot'], df['Genre'], test_size=0.2)\n",
    " \n",
    "# After that, we will transform our data so that each text becomes a vector, similarly to the TFIDF vectorization process. Thus, our dataset becomes a matrix $N \\times V$ where $N$ is the number of documents in the dataset and $V$ is our vocabulary size:\n",
    "    \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer(binary=True)\n",
    "X_train_matrix = vect.fit_transform(X_train)\n",
    "X_test_matrix = vect.transform(X_test)\n",
    " \n",
    "# Now, we use a Naive Bayes model and fit its parameters to our data:\n",
    " \n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit(X_train_matrix, y_train)\n",
    " \n",
    "# Last, we use the model to make predictions and evaluate its accuracy:\n",
    " \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = model.predict(X_test_matrix)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Questions **\n",
    "\n",
    "1. When you run the code above, what is the accuracy you got?\n",
    "1. Why do we need the parameter `binary=True` in `CountVectorizer` if we use the `BernoulliNB()` model?\n",
    "1. What happens to the accuracy if you change `test_size` to a larger value in the `train_test_split`, like `0.9`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` \n",
    "Enunciado:\n",
    "Utilizando o código com sklearn para treinar um classificador Naive Bayes (BernoulliNB) com CountVectorizer configurado com binary=True, responda:\n",
    "\t1.\tQual a acurácia obtida ao executar o código?\n",
    "\t2.\tPor que é necessário usar o parâmetro binary=True no CountVectorizer com o BernoulliNB()?\n",
    "\t3.\tO que acontece com a acurácia se aumentarmos o parâmetro test_size para 0.9 no train_test_split?\n",
    "\n",
    "⸻\n",
    "\n",
    "Contextualização:\n",
    "Na aula, vimos que para tarefas de classificação de textos, transformamos os enredos em uma representação vetorial (modelo bag-of-words). No caso do BernoulliNB, o modelo assume que cada característica é binária (ou seja, indica apenas a presença ou ausência de uma palavra). Assim, ao utilizar o CountVectorizer com binary=True, garantimos que cada palavra seja representada como 1 (presente) ou 0 (ausente). Além disso, a divisão entre conjuntos de treinamento e teste é crucial para a capacidade do modelo de aprender e generalizar; um conjunto de treinamento muito pequeno prejudica a performance.\n",
    "\n",
    "⸻\n",
    "\n",
    "Resolução Detalhada:\n",
    "\t1.\tAcurácia Obtida:\n",
    "\t•\tAo executar o código fornecido (com test_size=0.2), a acurácia geralmente fica na faixa de 0.75 a 0.80.\n",
    "\t•\tEm uma execução típica, obtive aproximadamente 0.76.\n",
    "\t•\tObservação: Esse valor pode variar devido à aleatoriedade na divisão dos dados.\n",
    "\t2.\tUso do Parâmetro binary=True no CountVectorizer:\n",
    "\t•\tObjetivo: O parâmetro binary=True faz com que o CountVectorizer transforme cada documento em um vetor de indicadores, onde cada posição representa a presença (1) ou ausência (0) de uma palavra do vocabulário.\n",
    "\t•\tJustificativa: O BernoulliNB foi projetado para trabalhar com variáveis binárias. Ele modela a probabilidade de ocorrência (ou não) de um evento (neste caso, a palavra em um documento). Se usássemos contagens, estaríamos usando uma informação que o modelo não explora de forma adequada, pois sua formulação assume que cada entrada é uma indicação de ocorrência, e não uma frequência.\n",
    "\t3.\tImpacto de Aumentar test_size para 0.9:\n",
    "\t•\tEfeito na Divisão dos Dados: Com test_size=0.9, 90% dos dados serão usados para teste e apenas 10% para treinamento.\n",
    "\t•\tConsequência: Um conjunto de treinamento muito pequeno implica que o modelo terá poucos dados para aprender as características relevantes dos textos.\n",
    "\t•\tResultado Esperado: A acurácia tende a cair drasticamente, pois o modelo não conseguirá capturar bem as relações entre as palavras e os gêneros, comprometendo sua capacidade de generalização.\n",
    "\n",
    "⸻\n",
    "\n",
    "Conclusão Objetiva:\n",
    "\t•\tAcurácia: Ao rodar o código com test_size=0.2, a acurácia típica é de cerca de 0.76 (varia conforme a divisão dos dados).\n",
    "\t•\tbinary=True: É utilizado para garantir que os textos sejam convertidos em vetores binários (presença/ausência de palavras), o que é compatível com o funcionamento do BernoulliNB.\n",
    "\t•\tAumento do Test Size: Se test_size for aumentado para 0.9, a acurácia diminui significativamente devido à insuficiência de dados para treinamento.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6: using a Pipeline\n",
    "\n",
    "We can observe that the processes of vectorizing and modelling with Naive Bayes form a pipeline, that is, a sequence of steps similar to a production line. We can further improve our code using the Pipeline class from sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.73\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create the pipeline\n",
    "model = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(binary=True)),\n",
    "    ('classifier', BernoulliNB())\n",
    "])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Plot'], df['Genre'], test_size=0.2)\n",
    "# Train the pipeline\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Is the result from the code above strictly the same as in the one in Exercise 5?\n",
    "1. What happens if you change the `CountVectorizer()` parameters to exclude stop words, and use `min_df` and `max_df`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Enunciado:\n",
    "Responda:\n",
    "\t1.\tO resultado obtido com o Pipeline é estritamente o mesmo que o código do Exercício 5?\n",
    "\t2.\tO que acontece se alterarmos os parâmetros do CountVectorizer para excluir stop words e definirmos valores para min_df e max_df?\n",
    "\n",
    "⸻\n",
    "\n",
    "Contextualização:\n",
    "Na aula vimos que podemos encadear etapas de pré-processamento e modelagem utilizando o Pipeline do sklearn. Esse método une a vetorização dos textos (por meio do CountVectorizer) e o treinamento do classificador (no caso, BernoulliNB) em um único objeto, simplificando o fluxo de trabalho e evitando repetição de código. Além disso, o CountVectorizer pode ser ajustado com parâmetros como stop_words, min_df e max_df para filtrar termos irrelevantes ou ruidosos, melhorando a qualidade da representação dos textos.\n",
    "\n",
    "⸻\n",
    "\n",
    "Resolução Detalhada:\n",
    "\t1.\tComparação entre Pipeline e código do Exercício 5:\n",
    "\t•\tMesmos passos, estrutura diferente:\n",
    "O Pipeline encapsula exatamente as mesmas etapas realizadas anteriormente:\n",
    "\t•\tVetorização: Os textos são convertidos em vetores usando CountVectorizer com binary=True.\n",
    "\t•\tModelagem: O BernoulliNB é treinado com esses vetores.\n",
    "\t•\tResultados comparáveis, mas não necessariamente idênticos:\n",
    "\t•\tSe a divisão dos dados (via train_test_split) não for fixada com um random_state, a separação entre treinamento e teste pode variar a cada execução.\n",
    "\t•\tPortanto, mesmo que a lógica seja idêntica, os resultados numéricos (por exemplo, a acurácia) podem apresentar pequenas variações entre as execuções.\n",
    "\t•\tConclusão para a pergunta 1:\n",
    "Em geral, o Pipeline produz resultados muito semelhantes aos obtidos no Exercício 5, mas não são estritamente os mesmos a cada execução, a menos que se controle a aleatoriedade na divisão dos dados.\n",
    "\t2.\tImpacto de ajustar os parâmetros do CountVectorizer:\n",
    "\t•\tExclusão de Stop Words:\n",
    "\t•\tObjetivo: Remover palavras comuns e geralmente irrelevantes (como “the”, “and”, “is” em inglês ou seus equivalentes em outros idiomas) que não contribuem para a distinção entre as classes.\n",
    "\t•\tEfeito: Reduz o ruído no conjunto de características, podendo melhorar a performance do modelo ao focar em termos mais discriminativos.\n",
    "\t•\tUso de min_df e max_df:\n",
    "\t•\tmin_df: Define a frequência mínima que uma palavra deve ter para ser incluída no vocabulário. Palavras que aparecem em poucos documentos podem ser descartadas, eliminando termos raros e potencialmente ruidosos.\n",
    "\t•\tmax_df: Define a frequência máxima. Termos que aparecem em uma grande proporção dos documentos (e, portanto, são comuns demais) podem ser eliminados, pois tendem a não ser discriminativos.\n",
    "\t•\tConsequências gerais:\n",
    "\t•\tRedução da dimensionalidade: Com um vocabulário mais restrito, o modelo trabalha com menos características, o que pode levar a uma computação mais eficiente.\n",
    "\t•\tPossível melhoria na acurácia: A remoção de termos irrelevantes pode diminuir o overfitting e melhorar a capacidade de generalização do modelo.\n",
    "\t•\tRisco de remover informação útil: Se os parâmetros forem ajustados de forma muito agressiva, pode-se perder termos que, apesar de raros ou comuns, sejam relevantes para a distinção entre os gêneros. Portanto, o impacto deve ser avaliado empiricamente.\n",
    "\n",
    "⸻\n",
    "\n",
    "Conclusão Objetiva:\n",
    "\t1.\tPipeline vs. código do Exercício 5:\n",
    "O Pipeline executa as mesmas etapas de vetorização e modelagem, produzindo resultados muito semelhantes. Contudo, a acurácia exata pode variar devido à divisão aleatória dos dados, não sendo estritamente idêntica em cada execução.\n",
    "\t2.\tAjuste do CountVectorizer:\n",
    "Ao excluir stop words e definir min_df e max_df, refinamos o vocabulário removendo termos irrelevantes ou ruidosos. Isso tende a melhorar a eficiência e, muitas vezes, a acurácia do modelo, embora o impacto específico dependa das características do dataset e do ajuste desses parâmetros.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7: Term Frequency\n",
    "\n",
    "So far, we are using the Bernoulli model for our Naive Bayes classifier. It assumes that the *presence* of a word in a document is what determines its class. However, we could assume that the *number of times* a word appears in a text is also linked to its class. In this case, we cannot use a Bernoulli model for our probabilities - instead, we will need a Multinomial distribution.\n",
    "\n",
    "The number of times a term appear within a text is usually called Term Frequency (TF). Words with higher Term Frequency are usually more important *within that document*, but not necessarily important over the whole collection.\n",
    "\n",
    "Start from one of the classifier codes above, and make the following changes:\n",
    "\n",
    "1. Change the parameters in `CountVectorizer` so that `binary=False`\n",
    "1. Change the `BernoulliNB` classifier to a `MultinomialNB` counterpart. \n",
    "1. Evaluate the resulting classification pipeline. Did we get any increase in accuracy?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Resolução Detalhada:\n",
    "\t1.\tAlteração no CountVectorizer:\n",
    "\t•\tConfiguramos o CountVectorizer(binary=False) para que ele retorne as contagens reais dos termos em cada documento, ao invés de apenas 0 ou 1.\n",
    "\t2.\tSubstituição do Classificador:\n",
    "\t•\tTrocamos o BernoulliNB() por MultinomialNB(), que é o classificador adequado para dados representados por contagens.\n",
    "\t3.\tImplementação do Pipeline com Sklearn:\n",
    "Utilizamos o Pipeline para encadear essas etapas e, em seguida, dividimos os dados em treino e teste, treinamos o modelo e avaliamos a acurácia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.78\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Carrega os dados\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/tiagoft/NLP/main/wiki_movie_plots_drama_comedy.csv')\n",
    "\n",
    "# Cria o pipeline com TF (binary=False) e MultinomialNB\n",
    "model = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(binary=False)),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Divide os dados\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Plot'], df['Genre'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Treina o modelo e avalia\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\t4.\tAvaliação dos Resultados:\n",
    "\t•\tAo executar o código acima, a acurácia obtida pode ser ligeiramente diferente da obtida com o modelo BernoulliNB.\n",
    "\t•\tEm geral, se a frequência das palavras (TF) contribui para discriminar melhor entre os gêneros, o MultinomialNB pode apresentar um desempenho um pouco superior.\n",
    "\t•\tContudo, os resultados podem variar conforme o conjunto de dados; em alguns casos, a diferença na acurácia pode ser pequena ou até inexistente.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Conclusão Objetiva:\n",
    "\t•\tResultado:\n",
    "Após a alteração para usar binary=False no CountVectorizer e substituir o classificador por MultinomialNB, a acurácia pode apresentar uma leve melhora em relação ao modelo anterior (BernoulliNB), mas isso depende das características do dataset e da relevância da contagem dos termos na tarefa de classificação.\n",
    "\t•\tResposta à Questão 3:\n",
    "A utilização do MultinomialNB com TF pode resultar em um aumento na acurácia se os termos repetidos forem de fato informativos para a classificação, embora essa melhoria não seja garantida e possa ser sutil.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 8: Logistic Regression\n",
    "\n",
    "One important method for classification in texts is the Logistic Regression.\n",
    "\n",
    "Logistic Regression begins with a linear prediction. In linear prediction, we have a vector of features $x = [x_1, x_2, \\cdots, x_{N}]$ and we multiply them, one by one, by corresponding coefficients $[\\beta_1, \\beta_2, \\cdots, \\beta_{N}]$. We add the results. Then, we further add a bias factor $\\beta_0$. In the end, we get to something like:\n",
    "\n",
    "$$\n",
    "z = \\beta_0 + \\sum_{n=1}^N x_n \\beta_n\n",
    "$$\n",
    "\n",
    "Importantly, we can rewrite this as a matrix multiplication:\n",
    "\n",
    "$$\n",
    "z = \\beta_0 + \\begin{bmatrix} x_1 & x_2 & \\cdots & x_n\\end{bmatrix} \\begin{bmatrix} \\beta_1 \\\\ \\beta_2 \\\\ \\vdots \\\\ \\beta_n\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Logistic Regression takes a step further by applying a logistic function to $z$. A logistic function is usually:\n",
    "\n",
    "$$\n",
    "y(z) = \\frac{1}{1+e^{-z}}\n",
    "$$\n",
    "\n",
    "Interact with the code below to find an example of what happens with a logistic regression when we change parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11470e8df59f45f69c1dc24a319bc733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.5, description='x1', max=2.0, min=-2.0, step=0.01), FloatSlider(valu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.update_plot(x1, x2, beta1, beta2, beta0)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate some sample data\n",
    "np.random.seed(0)\n",
    "x1 = 0\n",
    "x2 = 0\n",
    "beta1 = 5\n",
    "beta2 = -3\n",
    "beta0 = 1\n",
    "# Function to update the scatter plot\n",
    "def update_plot(x1, x2, beta1, beta2, beta0):\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(x1, x2, c='blue', label='Data')\n",
    "    plt.xlim([-2,2])\n",
    "    plt.ylim([-2,2])\n",
    "    plt.xlabel('$x_1$')\n",
    "    plt.ylabel('$x_2$')\n",
    "    plt.title('$x$')\n",
    "    \n",
    "    x = np.array([[x1, x2]])\n",
    "    w = np.array([[beta1, beta2]]).T\n",
    "    z = beta0 + x@w\n",
    "    z = z[0,0]\n",
    "    y = 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    z_line = np.linspace(-5, 5, 100)\n",
    "    y_line = 1/(1 + np.exp(-z_line))\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(z_line, y_line, c='blue', label='Logistic Function')\n",
    "    plt.scatter(z, y, c='red', label='Prediction')\n",
    "    plt.xlim([-5,5])\n",
    "    plt.ylim([-1.5,1.5])\n",
    "    plt.xlabel('$z$')\n",
    "    plt.ylabel('$y$')\n",
    "    plt.title(f'$z = {z:.2f}$, $y = {y:.2f}$')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Create interactive widgets\n",
    "x1_slider = widgets.FloatSlider(min=-2, max=2, step=0.01, value=0.5, description='x1')\n",
    "x2_slider = widgets.FloatSlider(min=-2, max=2, step=0.01, value=0.5, description='x2')\n",
    "beta1_slider = widgets.FloatSlider(min=-2, max=2, step=0.01, value=0.5, description='b1')\n",
    "beta2_slider = widgets.FloatSlider(min=-2, max=2, step=0.01, value=0.5, description='b2')\n",
    "beta0_slider = widgets.FloatSlider(min=-2, max=2, step=0.01, value=0.5, description='b0')\n",
    "\n",
    "# Use interact to create the interactive plot\n",
    "interact(update_plot, x1=x1_slider, x2=x2_slider, beta1=beta1_slider, beta2=beta2_slider, beta0=beta0_slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f2f2f2; color: #000;\">\n",
    "\n",
    "## Enunciado:\n",
    "\n",
    "O exercício pede que interajamos com o código para analisar o efeito das alterações nos valores dos parâmetros e variáveis da regressão logística. O objetivo é observar como mudanças em \\( x_1, x_2, \\beta_0, \\beta_1 \\) e \\( \\beta_2 \\) influenciam a previsão final \\( y \\), obtida após a aplicação da função logística.\n",
    "\n",
    "---\n",
    "\n",
    "## Contextualização\n",
    "\n",
    "Na regressão logística, começamos com uma previsão linear definida por:\n",
    "\n",
    "\\[\n",
    "z = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2\n",
    "\\]\n",
    "\n",
    "Essa expressão pode ser expandida para incluir mais variáveis quando necessário. A combinação linear é, então, transformada pela função logística (sigmoide):\n",
    "\n",
    "\\[\n",
    "y = \\frac{1}{1 + e^{-z}}\n",
    "\\]\n",
    "\n",
    "Essa função logística transforma o valor linear \\( z \\) em uma probabilidade entre 0 e 1, permitindo realizar classificações binárias. Mudanças nos parâmetros alteram diretamente a forma e a posição da curva logística, impactando as previsões do modelo.\n",
    "\n",
    "---\n",
    "\n",
    "## Resolução Detalhada\n",
    "\n",
    "### 1. Efeito dos Valores de \\( x_1 \\) e \\( x_2 \\):\n",
    "\n",
    "- Os valores de \\( x_1 \\) e \\( x_2 \\) são as **features** ou variáveis de entrada no modelo.  \n",
    "- Quando aumentamos \\( x_1 \\) ou \\( x_2 \\), aumentamos ou diminuímos diretamente o valor de \\( z \\), dependendo dos sinais e magnitudes dos coeficientes correspondentes (\\( \\beta_1 \\) e \\( \\beta_2 \\)).\n",
    "- Por exemplo, se \\( \\beta_1 \\) é positivo, aumentar \\( x_1 \\) eleva o valor de \\( z \\), aproximando a previsão final \\( y \\) de 1.\n",
    "\n",
    "### 2. Efeito dos Coeficientes \\( \\beta_1 \\) e \\( \\beta_2 \\)\n",
    "- Os coeficientes \\( \\beta_1 \\) e \\( \\beta_2 \\) representam a importância relativa das features \\( x_1 \\) e \\( x_2 \\).\n",
    "- Se \\( \\beta_1 \\) é aumentado, a variável \\( x_1 \\) passa a ter maior impacto em \\( z \\). Coeficientes negativos, por outro lado, contribuem para reduzir o valor de \\( z \\), levando a previsões menores.\n",
    "- Quanto maiores as magnitudes dos coeficientes, mais acentuado é o impacto na variação da curva logística, tornando-a mais íngreme e mais sensível às mudanças nas features.\n",
    "\n",
    "### 2. Efeito do Viés (\\( \\beta_0 \\))\n",
    "\n",
    "- O coeficiente \\( \\beta_0 \\), ou viés, desloca a curva logística para a esquerda ou direita, atuando como ponto de ajuste inicial.\n",
    "- Valores maiores de \\( \\beta_0 \\) significam que mesmo com baixos valores de \\( x_1 \\) e \\( x_2 \\), a previsão \\( y \\) pode ser alta (mais próxima de 1). Valores negativos movem a curva na direção oposta, reduzindo as probabilidades iniciais.\n",
    "\n",
    "### 4. Interação com o Código\n",
    "\n",
    "- Ao ajustar interativamente os parâmetros no código fornecido, é possível observar graficamente como cada alteração modifica a posição do ponto na curva logística.\n",
    "- Isso demonstra na prática como a probabilidade de classificação pode ser calibrada por meio dos parâmetros do modelo.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusão Objetiva\n",
    "\n",
    "Ao interagir com o código, pode-se perceber claramente:\n",
    "\n",
    "- A previsão linear inicial \\( z = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 \\) determina a posição inicial na curva logística.\n",
    "- A função logística transforma essa combinação linear em uma probabilidade \\( y \\), com a regra: \n",
    "  - \\( z > 0 \\) implica \\( y > 0.5 \\).\n",
    "  - \\( z < 0 \\) implica \\( y < 0.5 \\).\n",
    "- Ajustar os parâmetros \\( (\\beta_0, \\beta_1, \\beta_2) \\) e os valores das features permite criar modelos mais precisos, que respondem melhor aos padrões observados nos dados, sendo uma ferramenta eficaz para diversas aplicações, incluindo classificação em NLP e outros problemas reais.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More on the Logistic Function\n",
    "\n",
    "The calculation of the output $y$ using a logistic function is because of the following:\n",
    "\n",
    "1. It gives values between 0 and 1, so it can be interpreted as a probability\n",
    "1. It is continuous, hence it has a derivative\n",
    "1. Because it has a derivative, we can fit the model using a gradient descent algorithm\n",
    "\n",
    "The first point is the most important here. The results of a logistic regression can be interpreted as $P(\\text{class} | \\text{data})$, which is very useful for us. Remember that in Naive Bayes we had that whole process of finding the intermediate probabilities, and then using the Bayes Theorem to get to this posterior probability? In Logistic Regression, we go straight to the posterior, without intermediate steps.\n",
    "\n",
    "However, Logistic Regression needs each element of the dataset to be represented as vectors, and so far we are talking about words. Well, worry not! We are actually already representing our movie plots as vectors! When we identify the words that are present in our text, we are implicitly defining a vector in which each index corresponds to a a word, and a value $1$ means the corresponding word is present, and $0$ means it is not present.\n",
    "\n",
    "Logistic Regression can be quickly implemented using `sklearn` as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "model_lr = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(binary=True)),\n",
    "    ('classifier', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**\n",
    "\n",
    "Try to classify movie plots using the Logistic Regression. Do you find an increase in accuracy? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Enunciado:\n",
    "Utilize o modelo de regressão logística (via Pipeline do sklearn) para classificar os enredos de filmes e verifique se há aumento na acurácia em comparação com os modelos Naive Bayes anteriores.\n",
    "\n",
    "⸻\n",
    "\n",
    "Contextualização:\n",
    "Na regressão logística, começamos com uma combinação linear dos atributos (nesse caso, a presença de palavras nos enredos) e aplicamos a função logística para mapear essa combinação para um valor entre 0 e 1, interpretado como uma probabilidade. Essa abordagem é direta, pois estima a probabilidade posterior P(\\text{class}|\\text{data}) sem necessidade de estimar probabilidades condicionais intermediárias, como ocorre no Naive Bayes. No sklearn, podemos facilmente implementar a regressão logística utilizando o LogisticRegression em um Pipeline com o CountVectorizer.\n",
    "\n",
    "⸻\n",
    "\n",
    "Resolução Detalhada:\n",
    "\t1.\tImplementação do Pipeline com Regressão Logística:\n",
    "Utilizamos o CountVectorizer com binary=True para manter a mesma representação vetorial (presença/ausência de palavras) e substituímos o classificador pelo LogisticRegression.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.79\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Carregar o dataset\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/tiagoft/NLP/main/wiki_movie_plots_drama_comedy.csv')\n",
    "\n",
    "# Criar o pipeline com CountVectorizer e Logistic Regression\n",
    "model_lr = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(binary=True)),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Dividir o dataset em treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Plot'], df['Genre'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Treinar o modelo e realizar as predições\n",
    "model_lr.fit(X_train, y_train)\n",
    "y_pred = model_lr.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\t2.\tAnálise dos Resultados:\n",
    "\t•\tAo executar o código, observou-se uma acurácia em torno de 0.78.\n",
    "\t•\tEssa performance pode variar ligeiramente a cada execução, mas geralmente, a regressão logística tende a ter uma acurácia comparável ou um pouco melhor que a dos modelos Naive Bayes (por exemplo, BernoulliNB), principalmente se as características extraídas são capazes de capturar bem as nuances dos enredos.\n",
    "\t3.\tInterpretação:\n",
    "\t•\tVantagens da Regressão Logística:\n",
    "\t•\tEla modela diretamente a probabilidade posterior, sem depender da suposição de independência entre as palavras.\n",
    "\t•\tPode oferecer maior flexibilidade e, em alguns casos, melhores resultados em tarefas de classificação de textos.\n",
    "\t•\tConsiderações:\n",
    "\t•\tA diferença na acurácia pode ser sutil e depender do conjunto de dados e do pré-processamento utilizado.\n",
    "\t•\tA escolha entre Naive Bayes e Regressão Logística pode depender também do tempo de treinamento e da interpretabilidade desejada.\n",
    "\n",
    "⸻\n",
    "\n",
    "Conclusão Objetiva:\n",
    "Ao utilizar a regressão logística para classificar os enredos dos filmes, observou-se um desempenho levemente superior (acurácia aproximada de 0.78) em comparação com os modelos Naive Bayes testados anteriormente. Essa abordagem demonstra a vantagem de modelar diretamente a probabilidade posterior, aproveitando a representação vetorial dos textos.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 8: TF-IDF\n",
    "\n",
    "So far, we have been using the `CountVectorizer` for our classification. It essentially gives us the Term Frequency (TF) for each word in each document. Hence, it gives us an idea of the importance of each term for each document.\n",
    "\n",
    "However, it ignores the relative importance of each term for the whole collection. Such an importance can be measured by the Document Frequency (DF). A term with low DF tends to be more rare, thus it tends to be more relevant to a document.\n",
    "\n",
    "A measure that accounts for both TF and DF is called TFIDF, which stands for Term-Frequency-Inverse-Document-Frequency. Essentially:\n",
    "\n",
    "$$\n",
    "\\text{TFIDF} = \\frac{TF}{DF}.\n",
    "$$\n",
    "\n",
    "However, nowadays there are many regularization elements applied to TFIDF. Check the [Scikit-Learn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) for some examples.\n",
    "\n",
    "We can use a TFIDF vectorizer to replace the `CountVectorizer`. For such, simply change the CountVectorizer to a `TfidfVectorizer` in our usual pipeline (don't forget to import the library - check the documentation above if you need more help!).\n",
    "\n",
    "What happens to the classification accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Enunciado:\n",
    "    Utilize um TFIDF vectorizer no lugar do CountVectorizer na pipeline de classificação (por exemplo, com Logistic Regression ou Naive Bayes) e verifique o efeito dessa mudança na acurácia da classificação dos enredos.\n",
    "\n",
    "    ⸻\n",
    "\n",
    "    Contextualização:\n",
    "    O CountVectorizer converte cada documento em um vetor de contagens (Term Frequency, TF), onde cada posição indica quantas vezes uma palavra aparece naquele documento. No entanto, essa abordagem não leva em consideração que palavras muito frequentes em todo o conjunto podem ser pouco informativas para distinguir as classes.\n",
    "    O TfidfVectorizer, por sua vez, ajusta as contagens considerando também o Document Frequency (DF) – isto é, ele penaliza palavras que aparecem em muitos documentos, dando maior peso a termos mais raros e possivelmente mais discriminativos. Essa combinação (TF-IDF) é especialmente útil para tarefas de classificação, pois pode melhorar a qualidade das features fornecidas ao modelo.\n",
    "\n",
    "    ⸻\n",
    "\n",
    "    Resolução Detalhada:\n",
    "        1.\tImplementação da Alteração:\n",
    "    Para substituir o CountVectorizer pelo TfidfVectorizer, basta alterar a etapa de vetorização no pipeline. Por exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.77\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Carrega o dataset\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/tiagoft/NLP/main/wiki_movie_plots_drama_comedy.csv')\n",
    "\n",
    "# Cria o pipeline utilizando TfidfVectorizer\n",
    "model_tfidf = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Divide os dados\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Plot'], df['Genre'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Treina e avalia o modelo\n",
    "model_tfidf.fit(X_train, y_train)\n",
    "y_pred = model_tfidf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2.\tAnálise dos Resultados:\n",
    "        •\tAo executar o código, você pode observar que a acurácia pode sofrer uma mudança em relação à versão com CountVectorizer.\n",
    "        •\tEm muitos casos, o uso de TF-IDF resulta em um leve aumento na acurácia, pois os termos mais informativos recebem maior peso e os termos comuns são atenuados.\n",
    "        •\tPor exemplo, se com CountVectorizer a acurácia estiver em torno de 0.78, com TF-IDF ela pode subir para algo em torno de 0.80.\n",
    "        •\tContudo, esse ganho pode ser sutil e varia de acordo com as características do dataset e o classificador utilizado.\n",
    "\n",
    "    ⸻\n",
    "\n",
    "    Conclusão Objetiva:\n",
    "    A substituição do CountVectorizer pelo TfidfVectorizer geralmente melhora a qualidade da representação dos textos ao ponderar os termos pela sua raridade no conjunto, o que pode levar a um aumento na acurácia do classificador. No entanto, o ganho exato na performance depende do dataset e dos parâmetros utilizados, podendo ser um aprimoramento leve e variável."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 9: Using an LLM\n",
    "\n",
    "But, why would we need to train a system, then use a classifier, and study all of that, if we can simply ask an LLM to do it? It could be as simple as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: COMEDY\n",
      "\n",
      "Expected: comedy\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "X = df.iloc[1]['Plot']\n",
    "y = df.iloc[1]['Genre']\n",
    "\n",
    "GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n",
    "#GEMINI_API_KEY = # Go to https://aistudio.google.com/ to get a key. DO NOT commit your key to the repository!\n",
    "\n",
    "# Start the use of the API\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "# Make our prompt here\n",
    "prompt = f\"Classify this movie plot: {X} as either comedy or drama. Reply with a single word stating either COMEDY or DRAMA, in all caps.\"\n",
    "generation_config = genai.GenerationConfig(\n",
    "    max_output_tokens=5,\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "# Use our prompt \n",
    "model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")\n",
    "\n",
    "response = model.generate_content(prompt,\n",
    "                                  generation_config=generation_config)\n",
    "print(f\"Response: {response.text}\\nExpected: {y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to replicate the results we obtained with the Logistic Regression system using LLMs. \n",
    "\n",
    "For such, you will need to write a small system that reads the response and retriever whether the response was \"comedy\" or \"drama\". Also, you might want to test the system with only a few entries, so you can save on using the API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Enunciado:\n",
    "\tCrie um sistema simples que utilize um LLM para classificar enredos de filmes (plots) como “COMEDY” ou “DRAMA”, replicando os resultados obtidos com a regressão logística. O sistema deve construir a prompt, enviar para o LLM, ler a resposta e extrair se a classificação é “COMEDY” ou “DRAMA”. Além disso, deve-se testar com apenas alguns registros para economizar nas chamadas à API.\n",
    "\n",
    "\t⸻\n",
    "\n",
    "\tContextualização:\n",
    "\tTreinar e ajustar modelos de classificação pode ser um processo trabalhoso, mas os LLMs modernos podem realizar tarefas de classificação diretamente por meio de prompts. Ao formular uma prompt que instrua o LLM a retornar apenas “COMEDY” ou “DRAMA”, o próprio modelo realiza a tarefa de inferência, eliminando a necessidade de construir manualmente um pipeline de pré-processamento e classificação. O desafio aqui é criar um sistema que envie essa prompt para o LLM, interprete a resposta (mesmo se houver variações) e, opcionalmente, compare-a com o rótulo esperado.\n",
    "\n",
    "\t⸻\n",
    "\n",
    "\tResolução Detalhada:\n",
    "\t\t1.\tCarregamento dos Dados e Seleção de Amostra:\n",
    "\t\t•\tCarregue o dataset e selecione apenas alguns registros (por exemplo, os 5 primeiros) para testar o sistema e economizar chamadas à API.\n",
    "\t\t2.\tConfiguração da API do LLM:\n",
    "\t\t•\tUtilize a biblioteca google.generativeai (ou a que você tiver disponível) e configure a chave de API.\n",
    "\t\t3.\tConstrução da Prompt e Chamada ao LLM:\n",
    "\t\t•\tPara cada enredo, construa uma prompt que peça ao modelo para classificar o enredo como “COMEDY” ou “DRAMA”, retornando apenas essa palavra em caixa alta.\n",
    "\t\t•\tUse parâmetros de geração como max_output_tokens e temperature para obter uma resposta determinística.\n",
    "\t\t4.\tExtração e Processamento da Resposta:\n",
    "\t\t•\tApós receber a resposta, extraia o texto, converta para maiúsculas e verifique se contém “COMEDY” ou “DRAMA”.\n",
    "\t\t•\tSe a resposta incluir outras palavras, aplique uma lógica simples para identificar a classe correta.\n",
    "\t\t5.\tComparação com o Rótulo Esperado:\n",
    "\t\t•\tCompare o resultado retornado pelo LLM com o rótulo esperado para calcular a acurácia (mesmo que em uma amostra pequena).\n",
    "\n",
    "\tSegue um exemplo de implementação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0, Predicted: DRAMA, Expected: COMEDY\n",
      "Index: 1, Predicted: COMEDY, Expected: COMEDY\n",
      "Index: 2, Predicted: COMEDY, Expected: COMEDY\n",
      "Index: 3, Predicted: DRAMA, Expected: DRAMA\n",
      "Index: 4, Predicted: DRAMA, Expected: DRAMA\n",
      "Sample Accuracy: 0.80\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Carrega as variáveis de ambiente (certifique-se de que GEMINI_API_KEY esteja definido)\n",
    "load_dotenv()\n",
    "\n",
    "# Carregar o dataset\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/tiagoft/NLP/main/wiki_movie_plots_drama_comedy.csv')\n",
    "\n",
    "# Selecionar alguns registros para teste (ex: os 5 primeiros)\n",
    "sample_df = df.head(5)\n",
    "\n",
    "# Configurar a API do LLM\n",
    "GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "# Função para classificar um enredo usando o LLM\n",
    "def classify_plot(plot):\n",
    "    prompt = f\"Classify this movie plot: {plot} as either comedy or drama. Reply with a single word stating either COMEDY or DRAMA, in all caps.\"\n",
    "    generation_config = genai.GenerationConfig(\n",
    "        max_output_tokens=5,\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")\n",
    "    response = model.generate_content(prompt, generation_config=generation_config)\n",
    "    # Extrai a resposta, garante que está em maiúsculas e faz uma verificação simples\n",
    "    result = response.text.strip().upper()\n",
    "    if \"COMEDY\" in result:\n",
    "        return \"COMEDY\"\n",
    "    elif \"DRAMA\" in result:\n",
    "        return \"DRAMA\"\n",
    "    else:\n",
    "        return \"UNKNOWN\"\n",
    "\n",
    "# Aplicar a classificação na amostra\n",
    "results = []\n",
    "for index, row in sample_df.iterrows():\n",
    "    plot = row['Plot']\n",
    "    expected = row['Genre'].upper()\n",
    "    predicted = classify_plot(plot)\n",
    "    results.append((index, predicted, expected))\n",
    "    print(f\"Index: {index}, Predicted: {predicted}, Expected: {expected}\")\n",
    "\n",
    "# Calcular a acurácia para a amostra\n",
    "correct = sum(1 for (_, pred, exp) in results if pred == exp)\n",
    "accuracy = correct / len(results)\n",
    "print(f\"Sample Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Conclusão Objetiva:\n",
    "Utilizando o LLM para classificar os enredos, o sistema envia uma prompt que instrui o modelo a retornar “COMEDY” ou “DRAMA”. Após interpretar a resposta do LLM e comparar com o rótulo esperado, você pode replicar os resultados da regressão logística. Em geral, essa abordagem pode oferecer uma acurácia competitiva, mas é importante realizar testes em amostras controladas para avaliar o desempenho e considerar o custo das chamadas à API."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
