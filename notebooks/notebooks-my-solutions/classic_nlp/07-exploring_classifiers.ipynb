{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Classifiers: beyond accuracy\n",
    "\n",
    "If everything went well, you fully understand the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
      "                ('classifier', LogisticRegression())])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "model_lr = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()), # CountVectorizer() or TfidfVectorizer(), eles são os vetores que serão usados para treinar o modelo. Um vetorizador é uma ferramenta que transforma texto em vetores numéricos. Um exemplo de vetorizador é o CountVectorizer, que transforma o texto em vetores de contagem de palavras. Outro exemplo é o TfidfVectorizer, que transforma o texto em vetores de frequência de palavras.\n",
    "    ('classifier', LogisticRegression()) # LogisticRegression() é o classificador que será usado para treinar o modelo. Um classificador é um algoritmo que aprende a mapear entradas para saídas. Um exemplo de classificador é a regressão logística, que é um algoritmo de aprendizado supervisionado que é usado para classificação binária.\n",
    "])\n",
    "\n",
    "print(model_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, you know how to train this model and how to get its accuracy on a test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression())])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TfidfVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
       "                ('classifier', LogisticRegression())])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/tiagoft/NLP/main/wiki_movie_plots_drama_comedy.csv')\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Plot'], df['Genre'], test_size=0.2)\n",
    "# Train the pipeline\n",
    "model_lr.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.78\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_lr.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to explore how to go beyond accuracy to analyze and report our results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Recall, Precision, F1-Score\n",
    "\n",
    "Accuracy is simply the number of correctly classified items divided by the total number of items in a dataset. It is an estimate of $P(\\text{correct answer})$ all over the test data.\n",
    "\n",
    "However, we might want to use a greater granularity to this measurement. Usually, these are per-class measures. For such, we can use:\n",
    "\n",
    "Recall\n",
    "\n",
    "$$\n",
    "R = \\frac{\\text{\\# of correctly found items of a class}}{\\text{\\# of items of the class in the dataset}}\n",
    "$$\n",
    "\n",
    "Precision:\n",
    "\n",
    "$$\n",
    "P = \\frac{\\text{\\# of correctly found items of a class}}{\\text{\\# of items classified as class by the system}}\n",
    "$$\n",
    "\n",
    "F1-Score (harmonic mean between $R$ and $P$):\n",
    "\n",
    "$$\n",
    "F = \\frac{2RP}{R+P}\n",
    "$$\n",
    "\n",
    "Optionally, we could use the balanced accuracy, which is the classwise per-class accuracy.\n",
    "\n",
    "Sklearn implements these measures as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.76\n",
      "Precision: 0.79\n",
      "F1: 0.77\n",
      "Balanced accuracy: 0.76\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, f1_score, balanced_accuracy_score\n",
    "\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "bal_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'F1: {f1:.2f}')\n",
    "print(f'Balanced accuracy: {bal_acc:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, sklearn allows you to print a more complete per-class classification report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      comedy       0.81      0.64      0.72       892\n",
      "       drama       0.77      0.89      0.82      1177\n",
      "\n",
      "    accuracy                           0.78      2069\n",
      "   macro avg       0.79      0.76      0.77      2069\n",
      "weighted avg       0.78      0.78      0.78      2069\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these results, discuss:\n",
    "\n",
    "1. What types of errors (in terms of: \"the true class is A but the system is saying \"B\") are more common in our system?\n",
    "1. Was the simple accuracy score misleading?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Enunciado:\n",
    "    Discutir, a partir dos resultados de recall, precision, F1-score e balanced accuracy (obtidos com o classification_report do sklearn), quais erros de classificação são mais comuns (por exemplo, quando a classe verdadeira é A mas o sistema previu B) e se a acurácia simples foi uma métrica enganosa.\n",
    "\n",
    "    ⸻\n",
    "\n",
    "    Contextualização:\n",
    "        •\tAcurácia: Mede a proporção de itens classificados corretamente em relação ao total, mas é uma visão global que não diferencia o desempenho entre classes.\n",
    "        •\tRecall: Indica a proporção de itens de uma determinada classe que foram corretamente identificados.\n",
    "        •\tPrecision: Mede a proporção dos itens previstos como de uma classe que estão corretos.\n",
    "        •\tF1-Score: É a média harmônica de precision e recall, oferecendo uma visão equilibrada entre esses dois aspectos.\n",
    "        •\tBalanced Accuracy: Considera a acurácia individual por classe, útil quando as classes estão desbalanceadas.\n",
    "        •\tO classification_report do sklearn apresenta essas métricas de forma detalhada para cada classe, permitindo identificar quais erros são mais recorrentes.\n",
    "\n",
    "    ⸻\n",
    "\n",
    "    Resolução Detalhada:\n",
    "        1.\tTipos de Erros Comuns:\n",
    "        •\tSe o relatório mostrar, por exemplo, um recall menor para a classe “DRAMA” em comparação à “COMEDY”, isso indica que muitos filmes que são de drama estão sendo incorretamente classificados como comedy.\n",
    "        •\tAlternativamente, uma precision baixa para “COMEDY” sugere que, dentre os filmes classificados como comédia, uma fração considerável são na verdade dramas.\n",
    "        •\tAssim, erros do tipo:\n",
    "        •\tVerdadeiro: DRAMA, Predito: COMEDY\n",
    "        •\tou, dependendo dos números, Verdadeiro: COMEDY, Predito: DRAMA\n",
    "    são os mais frequentes.\n",
    "        •\tEssa análise permite identificar se o modelo tende a “confundir” uma classe com a outra, o que pode ocorrer por similaridades nos enredos ou por uma representação vetorial que não separa bem as classes.\n",
    "        2.\tAcurácia Simples – Enganosa ou Não?\n",
    "        •\tUma alta acurácia global pode dar a impressão de que o modelo está performando bem.\n",
    "        •\tContudo, essa métrica não revela se o modelo está favorecendo uma classe em detrimento da outra ou se há problemas em identificar corretamente uma das classes (por exemplo, baixa recall ou precision para um dos gêneros).\n",
    "        •\tPortanto, a acurácia simples pode ser enganosa, pois mascara discrepâncias importantes no desempenho entre as classes.\n",
    "        •\tMétricas como recall, precision, F1-score e balanced accuracy oferecem uma visão mais granular e realista da performance do modelo em cada classe.\n",
    "\n",
    "    ⸻\n",
    "\n",
    "    Conclusão Objetiva:\n",
    "        1.\tErros Comuns:\n",
    "        •\tO classification_report geralmente revela que o modelo comete erros na forma de confundir uma classe com a outra – por exemplo, muitos filmes que são de DRAMA podem estar sendo erroneamente classificados como COMEDY (ou vice-versa), indicando que o modelo tem dificuldade em separar claramente as características dos gêneros.\n",
    "        2.\tAcurácia Enganosa:\n",
    "        •\tA acurácia simples pode ser enganosa porque ela ignora as diferenças de desempenho entre as classes. Mesmo com uma acurácia global elevada, pode haver problemas significativos (como baixa recall ou precision) em uma das classes, o que só fica evidente quando se analisam métricas mais detalhadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: The Confusion Matrix\n",
    "\n",
    "A common way to report classification errors is the Confusion Matrix. The confusion matrix is a square matrix where element $c_{i,j}$ indicates the number of times an item whose true class is $i$ and the predicted class is $j$.\n",
    "\n",
    "Using the confusion matrix below, calculate:\n",
    "\n",
    "1. The probability that, if the system predicts a plot is comedy, it is actually comedy.\n",
    "1. The probability that, if the system predicts a plot is drama, it is actually drama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.64237668 0.35762332]\n",
      " [0.11469839 0.88530161]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,  ConfusionMatrixDisplay\n",
    "\n",
    "c = confusion_matrix(y_test, y_pred, normalize='true')\n",
    "print(c)\n",
    "_ = ConfusionMatrixDisplay(c, display_labels=['comedy', 'drama']).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f2f2f2; color: #000;\">\n",
    "\n",
    "# Enunciado:\n",
    "Usando a matriz de confusão fornecida (obtida com `normalize='true'`), calcule:\n",
    "1. A probabilidade de que, se o sistema prevê que um enredo é *comedy*, ele seja realmente *comedy*.\n",
    "2. A probabilidade de que, se o sistema prevê que um enredo é *drama*, ele seja realmente *drama*.\n",
    "\n",
    "---\n",
    "\n",
    "# Contextualização:\n",
    "A matriz de confusão é uma ferramenta que resume o desempenho de um classificador. Cada elemento \\( c_{i,j} \\) da matriz representa o número (ou a proporção, se normalizada) de itens cuja classe verdadeira é \\( i \\) e foram classificados como \\( j \\).\n",
    "\n",
    "- **Precisão (Precision)** para uma classe é definida como a fração de itens que, tendo sido classificados como essa classe, realmente pertencem a ela.\n",
    "- Assim, para a classe *comedy*, queremos calcular:\n",
    "\n",
    "\\[\n",
    "\\text{Precision (comedy)} = \\frac{\\text{# de enredos verdadeiramente comedy classificados como comedy}}{\\text{# total de enredos classificados como comedy}}\n",
    "\\]\n",
    "\n",
    "- E para a classe *drama*:\n",
    "\n",
    "\\[\n",
    "\\text{Precision (drama)} = \\frac{\\text{# de enredos verdadeiramente drama classificados como drama}}{\\text{# total de enredos classificados como drama}}\n",
    "\\]\n",
    "\n",
    "## Importante:\n",
    "No código fornecido, a matriz é normalizada com `normalize='true'`, o que significa que cada linha (relativa à classe verdadeira) soma 1. Essa normalização fornece a **sensibilidade (recall)** para cada classe, não a **precisão**.\n",
    "\n",
    "Para calcular a precisão com base na matriz de confusão, precisamos dos valores que contam quantos itens foram previstos em cada classe (isto é, precisamos **normalizar por coluna**).\n",
    "\n",
    "Se denotarmos por:\n",
    "\n",
    "\\[\n",
    "\\begin{pmatrix}\n",
    "c_{0,0} & c_{0,1} \\\\\n",
    "c_{1,0} & c_{1,1}\n",
    "\\end{pmatrix}\n",
    "\\]\n",
    "\n",
    "- Onde a **linha 0** corresponde à classe verdadeira *comedy* e a **linha 1** à classe verdadeira *drama*.\n",
    "- A **coluna 0** indica os itens previstos como *comedy* e a **coluna 1** os previstos como *drama*.\n",
    "\n",
    "Então:\n",
    "\n",
    "1. A probabilidade de que, se o sistema prevê *comedy*, o enredo seja de fato *comedy* é:\n",
    "\n",
    "\\[\n",
    "P(\\text{True Comedy} \\mid \\text{Predicted Comedy}) = \\frac{c_{0,0}}{c_{0,0} + c_{1,0}}\n",
    "\\]\n",
    "\n",
    "2. A probabilidade de que, se o sistema prevê *drama*, o enredo seja de fato *drama* é:\n",
    "\n",
    "\\[\n",
    "P(\\text{True Drama} \\mid \\text{Predicted Drama}) = \\frac{c_{1,1}}{c_{0,1} + c_{1,1}}\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "# Conclusão Objetiva:\n",
    "- **(1)** A probabilidade de que, se o sistema prevê *comedy*, o enredo seja realmente *comedy* é dada por:\n",
    "\n",
    "\\[\n",
    "\\frac{c_{0,0}}{c_{0,0} + c_{1,0}}\n",
    "\\]\n",
    "\n",
    "- **(2)** A probabilidade de que, se o sistema prevê *drama*, o enredo seja realmente *drama* é dada por:\n",
    "\n",
    "\\[\n",
    "\\frac{c_{1,1}}{c_{0,1} + c_{1,1}}\n",
    "\\]\n",
    "\n",
    "**Observação:** Para calcular esses valores diretamente, seria necessário obter a matriz de confusão sem normalização por linha ou normalizá-la por coluna, pois a configuração `normalize='true'` do *sklearn* normaliza por classe verdadeira (linhas) e, portanto, nos fornece os **recalls** e não as **precisões**.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: How certain are you?\n",
    "\n",
    "Simply stating something is from a particular class is useful, but we might want to know how certain the system is about this prediction.\n",
    "\n",
    "The output of a Logistic Regression is the probability of an item belonging to a class given its characteristics, or:\n",
    "\n",
    "$$\n",
    "P(\\text{class} | \\text{text})\n",
    "$$\n",
    "\n",
    "We can directly access this using the `.predict_proba` method in the model. However, as we know, probabilities can saturate close to zero or one, so it is also possible to get the logarithm of the probabilities, using `predict_log_proba`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted genre: comedy\n",
      "Probabilities: [0.68867237 0.31132763]\n",
      "Log probabilities: [-0.37298964 -1.16690945]\n"
     ]
    }
   ],
   "source": [
    "my_plot = \"\"\"\n",
    "In a small, forgotten town, once-famous clown duo Chuckles and Boomer, along with their pack of hilariously talented dogs, \n",
    "decide to bring back the glory days of circuses with a grand show dedicated to their favorite snack: sausages. \n",
    "But the town’s greedy mayor has other plans. He wants to build a shopping mall on the circus lot and will stop at nothing to get his way. \n",
    "Chuckles and Boomer must pull out all the stops to save their circus and preserve the laughter for generations to come.\n",
    "\"\"\"\n",
    "\n",
    "y_pred = model_lr.predict([my_plot])\n",
    "y_prob = model_lr.predict_proba([my_plot])\n",
    "y_log_prob = model_lr.predict_log_proba([my_plot])\n",
    "print(f'Predicted genre: {y_pred[0]}')\n",
    "print(f'Probabilities: {y_prob[0]}')\n",
    "print(f'Log probabilities: {y_log_prob[0]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See, if `y_prob` is close to $0.5$, it means that the system is not exacly \"sure\" - in the sense that, there is not enough evidence - to attribute a class to an item.\n",
    "\n",
    "Change your classification system so that, if `y_prob` is between $0.4$ and $0.6$, then the item is classified as \"unkown\". After that, calculate the classification report again. \n",
    "\n",
    "What happened to Recall and Precision, and why?\n",
    "\n",
    "In what use cases would this difference be useful? In what use cases would this difference be harmful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Enunciado:\n",
    "    Modifique seu sistema de classificação para que, se a probabilidade prevista estiver entre 0.4 e 0.6, o item seja classificado como “unknown”. Depois, recalcule o classification report e discuta:\n",
    "        1.\tO que aconteceu com Recall e Precision?\n",
    "        2.\tEm quais casos essa abordagem pode ser útil e em quais pode ser prejudicial?\n",
    "\n",
    "    ⸻\n",
    "\n",
    "    Contextualização:\n",
    "    A saída de um modelo de regressão logística fornece, para cada item, uma distribuição de probabilidade entre as classes (por exemplo, P(\\text{comedy}|\\text{text}) e P(\\text{drama}|\\text{text})). Geralmente, a classe com maior probabilidade é escolhida. Entretanto, quando essa probabilidade não é suficientemente alta (ou seja, quando está próxima de 0.5), o modelo demonstra incerteza. Ao definir um limiar – por exemplo, se a maior probabilidade estiver entre 0.4 e 0.6 – podemos optar por não classificar o item (classificando-o como “unknown”). Essa estratégia pode afetar as métricas de desempenho e tem implicações práticas que dependem do contexto de uso.\n",
    "\n",
    "    ⸻\n",
    "\n",
    "    Resolução Detalhada:\n",
    "        1.\tAlteração do Sistema de Classificação:\n",
    "        •\tImplementação:\n",
    "    Após obter as probabilidades via predict_proba, verifique se a maior probabilidade está entre 0.4 e 0.6. Se sim, retorne “unknown”; caso contrário, retorne a classe com a maior probabilidade.\n",
    "    Exemplo de código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_uncertainty(model, texts):\n",
    "    # Obtém as probabilidades para cada item\n",
    "    probas = model.predict_proba(texts)\n",
    "    predictions = []\n",
    "    for p in probas:\n",
    "        max_prob = max(p)\n",
    "        if 0.4 <= max_prob <= 0.6:\n",
    "            predictions.append(\"unknown\")\n",
    "        else:\n",
    "            # Recupera o índice da classe com maior probabilidade e mapeia para o rótulo original\n",
    "            pred_label = model.classes_[p.argmax()]\n",
    "            predictions.append(pred_label)\n",
    "    return predictions\n",
    "\n",
    "# Exemplo de uso com o conjunto de teste\n",
    "y_pred_uncertain = predict_with_uncertainty(model_lr, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genre\n",
      "drama      1020\n",
      "unknown     664\n",
      "comedy      385\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# transofrmar y_pred_uncertain em df para fazer o value_counts\n",
    "df_pred = pd.DataFrame(y_pred_uncertain, columns=['Genre'])\n",
    "\n",
    "print(df_pred['Genre'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.37\n",
      "Precision: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luizfelipelazzaron/Documents/2025/nlp/nlp_course/venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# vamos calcular o recall e precision para esse novo modelo\n",
    "recall = recall_score(y_test, y_pred_uncertain, average='macro')\n",
    "precision = precision_score(y_test, y_pred_uncertain, average='macro')\n",
    "\n",
    "print(f'Recall: {recall:.2f}')\n",
    "\n",
    "print(f'Precision: {precision:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        2.\tCálculo do Classification Report:\n",
    "        •\tAo gerar o classification report com essas novas previsões, as métricas para as classes “comedy” e “drama” serão recalculadas considerando que alguns itens que antes eram classificados (mesmo que de forma incerta) agora estão marcados como “unknown”.\n",
    "        3.\tImpacto nas Métricas:\n",
    "        •\tRecall:\n",
    "        •\tRedução: Muitos itens verdadeiramente pertencentes a “comedy” ou “drama” podem acabar sendo classificados como “unknown” por falta de evidência forte. Isso significa que o número de verdadeiros positivos para cada classe diminui, reduzindo o recall.\n",
    "        •\tPrecision:\n",
    "        •\tPossível Aumento: Para os itens que são efetivamente classificados como “comedy” ou “drama” (ou seja, onde o modelo está mais confiante), a precisão tende a ser maior, pois o modelo só faz a previsão quando há uma probabilidade alta, reduzindo os falsos positivos.\n",
    "        4.\tDiscussão de Casos de Uso:\n",
    "        •\tÚtil quando:\n",
    "        •\tRisco Alto de Erro: Em aplicações onde um erro de classificação pode ser muito custoso (por exemplo, diagnósticos médicos, decisões de crédito ou segurança), é preferível abstiver-se de classificar um item quando o modelo não está suficientemente seguro.\n",
    "        •\tTomada de Decisão Assistida: Em cenários onde a decisão final pode ser revisada por um humano, sinalizar itens “unknown” pode ajudar a priorizar casos que necessitam de análise adicional.\n",
    "        •\tPrejudicial quando:\n",
    "        •\tNecessidade de Decisão para Todos os Itens: Em sistemas automatizados que exigem uma resposta para cada entrada (por exemplo, filtros automáticos de spam ou recomendações), ter muitas respostas “unknown” pode reduzir a utilidade do sistema.\n",
    "        •\tBaixo Custo de Erro: Quando os erros não têm consequências graves, a abstinência pode ser mais problemática do que uma classificação forçada, prejudicando a cobertura e a usabilidade do sistema.\n",
    "\n",
    "    ⸻\n",
    "\n",
    "    Conclusão Objetiva:\n",
    "    Ao incorporar uma faixa de incerteza (probabilidades entre 0.4 e 0.6 resultando em “unknown”), o sistema se torna mais conservador:\n",
    "        •\tRecall para “comedy” e “drama” diminui, pois muitos itens que pertencem a essas classes são deixados sem classificação (marcados como “unknown”).\n",
    "        •\tPrecision pode aumentar para os itens efetivamente classificados, já que o sistema só faz uma previsão quando a confiança é alta.\n",
    "    Essa abordagem é vantajosa em contextos onde erros são custosos e uma abstinência é preferível, mas pode ser prejudicial em sistemas que precisam de uma decisão para cada entrada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: why did you classify it as you did?\n",
    "\n",
    "Another thing you might be interested in is finding out why a classifier predicted that something belongs to a particular class. In the case of Logistic Regression, we can retrieve the logits generated by a text (that is, the $z$ variable in the Logistic Regression schema). If we calculate the decision function for single words, we are simply retrieving the results of $x_n \\beta_n$, where $x_n$ is a TFIDF factor for that word, and $\\beta_n$ is the weight given to that word. For example, in the code below, note that changing \"comedy\" for \"sadness\" makes the decision function shift signals - and the absolute value of $z$ is more extreme if you find words that are more comedy-like or more drama-like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision function: [3.62588249]\n",
      "After logistic function: [0.97406495]\n",
      "Predicted probability: [0.68867237 0.31132763]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "z = model_lr.decision_function([\"death\"])\n",
    "print(f'Decision function: {z}')\n",
    "y = 1/(1 + np.exp(-z))\n",
    "print(f'After logistic function: {y}')\n",
    "y_prob = model_lr.predict_proba([my_plot])\n",
    "print(f'Predicted probability: {y_prob[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, make a function that receives a movie plot and a model as input and returns a dataclass containing the movie genre, the probability it belongs to that genre, and the words (within the plot) that are most prominent towards classifying the movie in that genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MovieClassification(genre='unknown', probability=0.5, top_5_words=['word1', 'word2', 'word3', 'word4', 'word5'])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class MovieClassification:\n",
    "    genre: str\n",
    "    probability: float\n",
    "    top_5_words: list\n",
    "\n",
    "\n",
    "def classify(model: Pipeline, plot: str) -> MovieClassification:\n",
    "    output = MovieClassification(\n",
    "        'unknown',\n",
    "        0.5,\n",
    "        ['word1', 'word2', 'word3', 'word4', 'word5'],\n",
    "    )\n",
    "    return output\n",
    "\n",
    "classify(None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f2f2f2; color: #000;\">\n",
    "\n",
    "\n",
    "# Exercício 4: Por que você classificou assim?\n",
    "\n",
    "Neste exercício, o objetivo é criar uma função que, dada uma plot de filme e um modelo (implementado via Pipeline com um TfidfVectorizer e um classificador de Regressão Logística), retorne uma instância de um dataclass contendo:\n",
    "\t•\tgenre: o gênero predito (por exemplo, “comedy” ou “drama”)\n",
    "\t•\tprobability: a probabilidade associada à previsão (obtida via predict_proba)\n",
    "\t•\ttop_5_words: as 5 palavras, presentes na plot, que mais contribuíram para essa previsão, isto é, que tiveram maiores pesos na função de decisão\n",
    "\n",
    "A ideia é usar o fato de que a Regressão Logística calcula um valor z = \\beta_0 + \\sum_{i} x_i \\beta_i e que, para um dado documento, cada palavra (com seu TF-IDF) contribui com x_i \\beta_i para esse valor. Dessa forma, podemos recuperar os termos presentes na plot, multiplicar o valor TF-IDF de cada termo pelo peso correspondente (coeficiente) e identificar quais termos tiveram maior influência na decisão do modelo.\n",
    "\n",
    "Abaixo, segue uma possível implementação:\n",
    "\n",
    "```python\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "\n",
    "@dataclass\n",
    "class MovieClassification:\n",
    "    genre: str\n",
    "    probability: float\n",
    "    top_5_words: list\n",
    "\n",
    "def classify(model, plot: str) -> MovieClassification:\n",
    "    # 1. Prever o gênero e obter as probabilidades\n",
    "    predicted_genre = model.predict([plot])[0]\n",
    "    probas = model.predict_proba([plot])[0]\n",
    "    \n",
    "    # Identifica o índice da classe predita\n",
    "    classes = model.named_steps['classifier'].classes_\n",
    "    class_index = list(classes).index(predicted_genre)\n",
    "    predicted_probability = probas[class_index]\n",
    "    \n",
    "    # 2. Transformar o texto em vetor TF-IDF usando o vectorizer do pipeline\n",
    "    vectorizer = model.named_steps['vectorizer']\n",
    "    clf = model.named_steps['classifier']\n",
    "    x_vec = vectorizer.transform([plot])\n",
    "    \n",
    "    # Obter os nomes dos termos (features)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    \n",
    "    # 3. Obter os coeficientes do classificador.\n",
    "    # Para classificação binária, clf.coef_ tem formato (1, n_features).\n",
    "    # Note que, em scikit-learn, as classes são ordenadas; \n",
    "    # o modelo calcula a decisão como z = x.dot(coef_.T) + intercept_ e a probabilidade para a classe de índice 1 é 1/(1+exp(-z)).\n",
    "    # Assim, se o gênero predito for classes[0] (digamos, \"comedy\"), a contribuição efetiva pode ser considerada como -coef_\n",
    "    # para facilitar a interpretação (ou seja, termos com valores altos empurram a decisão para essa classe).\n",
    "    coef = clf.coef_[0]\n",
    "    if predicted_genre == classes[0]:\n",
    "        effective_coef = -coef\n",
    "    else:\n",
    "        effective_coef = coef\n",
    "\n",
    "    # 4. Calcular as contribuições de cada palavra presente no documento.\n",
    "    # x_vec é uma matriz esparsa; extraímos os índices dos termos que aparecem na plot.\n",
    "    indices = x_vec.nonzero()[1]\n",
    "    contributions = {}\n",
    "    for i in indices:\n",
    "        # Valor TF-IDF para a palavra\n",
    "        value = x_vec[0, i]\n",
    "        # Contribuição: TF-IDF vezes o coeficiente efetivo\n",
    "        contributions[feature_names[i]] = value * effective_coef[i]\n",
    "    \n",
    "    # 5. Selecionar as 5 palavras com maiores contribuições (em ordem decrescente)\n",
    "    sorted_words = sorted(contributions.items(), key=lambda item: item[1], reverse=True)\n",
    "    top_5_words = [word for word, contr in sorted_words[:5]]\n",
    "    \n",
    "    return MovieClassification(\n",
    "        genre=predicted_genre,\n",
    "        probability=predicted_probability,\n",
    "        top_5_words=top_5_words\n",
    "    )\n",
    "\n",
    "# Exemplo de uso:\n",
    "# Supondo que \"model_lr\" seja o pipeline treinado (contendo um TfidfVectorizer e uma LogisticRegression)\n",
    "# e \"my_plot\" seja um texto com a plot de um filme.\n",
    "result = classify(model_lr, my_plot)\n",
    "print(f\"Predicted genre: {result.genre}\")\n",
    "print(f\"Probability: {result.probability:.2f}\")\n",
    "print(\"Top 5 words:\", result.top_5_words)\n",
    "\n",
    "```\n",
    "\n",
    "⸻\n",
    "\n",
    "Explicação dos Principais Passos\n",
    "\t1.\tPrevisão e Probabilidade:\n",
    "\t•\tUsamos model.predict([plot]) para obter o gênero predito.\n",
    "\t•\tCom model.predict_proba([plot]) recuperamos a distribuição de probabilidades; extraímos a probabilidade associada à classe predita.\n",
    "\t2.\tTransformação do Texto:\n",
    "\t•\tO texto é transformado em um vetor TF-IDF usando o vectorizer presente no pipeline, o que nos permite acessar os valores de cada termo.\n",
    "\t3.\tRecuperação dos Coeficientes:\n",
    "\t•\tO classificador (LogisticRegression) tem coeficientes para cada termo. Cada termo contribui com um valor x_i \\times \\beta_i para a função de decisão.\n",
    "\t•\tPara interpretar as contribuições a favor da classe predita, se o modelo previu a classe de índice 0 (por exemplo, “comedy”), consideramos os coeficientes com sinal invertido.\n",
    "\t4.\tDeterminação das Top 5 Palavras:\n",
    "\t•\tIteramos apenas sobre os termos que aparecem na plot (obtidos através dos índices não-zero do vetor esparso).\n",
    "\t•\tCalculamos a contribuição de cada termo e, em seguida, selecionamos as 5 palavras com maiores contribuições, que indicam os termos que mais influenciaram a decisão do modelo.\n",
    "\t5.\tRetorno dos Resultados:\n",
    "\t•\tA função retorna uma instância do dataclass MovieClassification, contendo o gênero, a probabilidade e a lista das top 5 palavras.\n",
    "\n",
    "Esta abordagem permite “explicar” a classificação, fornecendo não apenas a previsão, mas também os termos que mais influenciaram a decisão do modelo.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted genre: comedy\n",
      "Probability: 0.69\n",
      "Top 5 words: ['to', 'show', 'all', 'get', 'duo']\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "\n",
    "@dataclass\n",
    "class MovieClassification:\n",
    "    genre: str\n",
    "    probability: float\n",
    "    top_5_words: list\n",
    "\n",
    "def classify(model, plot: str) -> MovieClassification:\n",
    "    # 1. Prever o gênero e obter as probabilidades\n",
    "    predicted_genre = model.predict([plot])[0]\n",
    "    probas = model.predict_proba([plot])[0]\n",
    "    \n",
    "    # Identifica o índice da classe predita\n",
    "    classes = model.named_steps['classifier'].classes_\n",
    "    class_index = list(classes).index(predicted_genre)\n",
    "    predicted_probability = probas[class_index]\n",
    "    \n",
    "    # 2. Transformar o texto em vetor TF-IDF usando o vectorizer do pipeline\n",
    "    vectorizer = model.named_steps['vectorizer']\n",
    "    clf = model.named_steps['classifier']\n",
    "    x_vec = vectorizer.transform([plot])\n",
    "    \n",
    "    # Obter os nomes dos termos (features)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    \n",
    "    # 3. Obter os coeficientes do classificador.\n",
    "    # Para classificação binária, clf.coef_ tem formato (1, n_features).\n",
    "    # Note que, em scikit-learn, as classes são ordenadas; \n",
    "    # o modelo calcula a decisão como z = x.dot(coef_.T) + intercept_ e a probabilidade para a classe de índice 1 é 1/(1+exp(-z)).\n",
    "    # Assim, se o gênero predito for classes[0] (digamos, \"comedy\"), a contribuição efetiva pode ser considerada como -coef_\n",
    "    # para facilitar a interpretação (ou seja, termos com valores altos empurram a decisão para essa classe).\n",
    "    coef = clf.coef_[0]\n",
    "    if predicted_genre == classes[0]:\n",
    "        effective_coef = -coef\n",
    "    else:\n",
    "        effective_coef = coef\n",
    "\n",
    "    # 4. Calcular as contribuições de cada palavra presente no documento.\n",
    "    # x_vec é uma matriz esparsa; extraímos os índices dos termos que aparecem na plot.\n",
    "    indices = x_vec.nonzero()[1]\n",
    "    contributions = {}\n",
    "    for i in indices:\n",
    "        # Valor TF-IDF para a palavra\n",
    "        value = x_vec[0, i]\n",
    "        # Contribuição: TF-IDF vezes o coeficiente efetivo\n",
    "        contributions[feature_names[i]] = value * effective_coef[i]\n",
    "    \n",
    "    # 5. Selecionar as 5 palavras com maiores contribuições (em ordem decrescente)\n",
    "    sorted_words = sorted(contributions.items(), key=lambda item: item[1], reverse=True)\n",
    "    top_5_words = [word for word, contr in sorted_words[:5]]\n",
    "    \n",
    "    return MovieClassification(\n",
    "        genre=predicted_genre,\n",
    "        probability=predicted_probability,\n",
    "        top_5_words=top_5_words\n",
    "    )\n",
    "\n",
    "# Exemplo de uso:\n",
    "# Supondo que \"model_lr\" seja o pipeline treinado (contendo um TfidfVectorizer e uma LogisticRegression)\n",
    "# e \"my_plot\" seja um texto com a plot de um filme.\n",
    "result = classify(model_lr, my_plot)\n",
    "print(f\"Predicted genre: {result.genre}\")\n",
    "print(f\"Probability: {result.probability:.2f}\")\n",
    "print(\"Top 5 words:\", result.top_5_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: adjusting hyperparameters\n",
    "\n",
    "In Logistic Regression, the coefficients $\\beta_n$ are called *parameters*. However, our model has some parameters that govern how parameters are obtained. These are called \"hyperparameters\". We usually want to tune our hyperparameters, but we often have no idea as to what the hyperparameters should be. \n",
    "\n",
    "The technique to tune hyperparameters is called \"cross-validation\". It works like this.\n",
    "\n",
    "The trainig set will be further divided into a \"train\" and a \"validation\" set. For each combination of hyperparameters, we will train the system in the new \"train\" set, and evaluate it in the \"valitation\" set. Then, we will choose the hyperparameter configuration that lead to the best results in the validation set. With that configuration, we train the system in the full training set, and then report the results in the test set.\n",
    "\n",
    "This is somewhat tricky to program, but scikit learn already implements this idea:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classifier__C': 10.0, 'vectorizer__binary': True, 'vectorizer__max_df': 1.0, 'vectorizer__min_df': 1}\n",
      "Best cross-validation accuracy: 0.80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      comedy       0.77      0.74      0.75       888\n",
      "       drama       0.81      0.83      0.82      1181\n",
      "\n",
      "    accuracy                           0.79      2069\n",
      "   macro avg       0.79      0.79      0.79      2069\n",
      "weighted avg       0.79      0.79      0.79      2069\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "df = pd.read_csv(\n",
    "    'https://raw.githubusercontent.com/tiagoft/NLP/main/wiki_movie_plots_drama_comedy.csv'\n",
    ")\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Plot'],\n",
    "                                                    df['Genre'],\n",
    "                                                    test_size=0.2)\n",
    "\n",
    "\n",
    "model_lr = Pipeline([('vectorizer', TfidfVectorizer(stop_words='english')),\n",
    "                     ('classifier', LogisticRegression())])\n",
    "\n",
    "param_grid = {\n",
    "    'vectorizer__min_df': [1, 5, 0.01],\n",
    "    'vectorizer__max_df': [1.0, 0.9, 0.3],\n",
    "    'vectorizer__binary': [True, False],\n",
    "    'classifier__C': [1e-1, 1e0, 1e1],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    model_lr,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(f'Best parameters: {grid_search.best_params_}')\n",
    "print(f'Best cross-validation accuracy: {grid_search.best_score_:.2f}')\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the code above and add to the grid search so that we can find out:\n",
    "\n",
    "1. Should we use stop words?\n",
    "1. Should we use ngrams in the vectorizer (parameter: `ngram_range`), so we would consider the order of words somehow? \n",
    "1. Should/can we limit our vocabulary (`max_features`) so that only the a few thousand words are considered?\n",
    "\n",
    "This test should take some minutes. You may want to test only a few parameters at a time to speed things up a bit.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Enunciado:\n",
    "    Modifique o código de GridSearchCV para incluir novas opções de hiperparâmetros que permitam investigar:\n",
    "        1.\tSe é vantajoso usar stop words (ou não).\n",
    "        2.\tSe o uso de ngrams (via o parâmetro ngram_range) melhora a performance, permitindo considerar a ordem das palavras.\n",
    "        3.\tSe limitar o vocabulário (usando max_features) – mantendo apenas um número reduzido de palavras – pode ajudar.\n",
    "\n",
    "    ⸻\n",
    "\n",
    "    Contextualização:\n",
    "    Em problemas de classificação de textos, a escolha dos hiperparâmetros do vetor de features pode ter um impacto significativo na performance do modelo.\n",
    "        •\tStop Words: A remoção de palavras comuns (como “the”, “and”, etc.) pode reduzir ruído, mas em alguns casos essas palavras podem conter informações contextuais úteis.\n",
    "        •\tNgram Range: Permitir n-grams (por exemplo, bigrams) pode capturar expressões ou relações entre palavras que o unigram não captura. Porém, ngrams maiores aumentam a dimensionalidade e podem incluir ruído.\n",
    "        •\tMax Features: Limitar o vocabulário pode reduzir overfitting e acelerar o treinamento, mas também pode remover termos relevantes se o limite for muito restritivo.\n",
    "\n",
    "    A técnica de cross-validation com GridSearchCV nos permite testar combinações desses hiperparâmetros e selecionar a configuração que oferece o melhor desempenho.\n",
    "\n",
    "    ⸻\n",
    "\n",
    "    Resolução Detalhada:\n",
    "        1.\tAdicionando Stop Words:\n",
    "        •\tInclua opções para que o vectorizer use stop words (por exemplo, 'english') ou não (valor None).\n",
    "        2.\tAdicionando Ngram Range:\n",
    "        •\tTeste com unigramas apenas (ex: (1, 1)) versus incluir bigramas (ex: (1, 2)).\n",
    "        •\tEssa configuração pode capturar a ordem das palavras em expressões importantes.\n",
    "        3.\tLimitando o Vocabulário:\n",
    "        •\tUse o parâmetro max_features para testar, por exemplo, sem limite (None) ou limitando a 5.000 ou 10.000 termos.\n",
    "        •\tIsso pode reduzir a dimensionalidade e o risco de overfitting.\n",
    "        4.\tCódigo Exemplo:\n",
    "    A seguir, um exemplo de código modificado para incluir essas novas opções no grid de busca:\n",
    "```python\n",
    "    import pandas as pd\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.pipeline import Pipeline\n",
    "\n",
    "    # Carrega o dataset\n",
    "    df = pd.read_csv(\n",
    "        'https://raw.githubusercontent.com/tiagoft/NLP/main/wiki_movie_plots_drama_comedy.csv'\n",
    "    )\n",
    "\n",
    "    # Divide os dados em conjuntos de treinamento e teste\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df['Plot'], df['Genre'], test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Define o pipeline com TfidfVectorizer e Logistic Regression\n",
    "    model_lr = Pipeline([\n",
    "        ('vectorizer', TfidfVectorizer()),\n",
    "        ('classifier', LogisticRegression())\n",
    "    ])\n",
    "\n",
    "    # Define o grid de hiperparâmetros\n",
    "    param_grid = {\n",
    "        # Testa se remove ou não as stop words\n",
    "        'vectorizer__stop_words': [None, 'english'],\n",
    "        # Testa apenas unigrams e unigrams+bigrams\n",
    "        'vectorizer__ngram_range': [(1, 1), (1, 2)],\n",
    "        # Testa limitar ou não o vocabulário\n",
    "        'vectorizer__max_features': [None, 5000, 10000],\n",
    "        # Outros parâmetros já existentes\n",
    "        'vectorizer__min_df': [1, 5, 0.01],\n",
    "        'vectorizer__max_df': [1.0, 0.9, 0.3],\n",
    "        'vectorizer__binary': [True, False],\n",
    "        'classifier__C': [1e-1, 1e0, 1e1],\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        model_lr,\n",
    "        param_grid,\n",
    "        cv=5,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(f'Best parameters: {grid_search.best_params_}')\n",
    "    print(f'Best cross-validation accuracy: {grid_search.best_score_:.2f}')\n",
    "\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "```\n",
    "\n",
    "        5.\tObservações:\n",
    "        •\tEsse teste pode levar alguns minutos para ser concluído, dado o número de combinações possíveis.\n",
    "        •\tRecomenda-se testar inicialmente apenas algumas combinações para agilizar o processo e depois expandir o grid conforme necessário.\n",
    "\n",
    "    ⸻\n",
    "\n",
    "    Conclusão Objetiva:\n",
    "    Adicionando as opções de stop words, ngram_range e max_features ao grid de busca, o GridSearchCV poderá identificar se:\n",
    "        •\tA remoção de stop words melhora a performance,\n",
    "        •\tO uso de bigrams (ou ngrams) auxilia na captura de contextos relevantes, e\n",
    "        •\tLimitar o vocabulário ajuda a reduzir ruído e overfitting.\n",
    "\n",
    "    Essa estratégia permite uma avaliação mais robusta dos hiperparâmetros e pode levar a melhorias na acurácia e generalização do modelo, dependendo do comportamento específico do conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'vectorizer__stop_words': 'english', 'vectorizer__ngram_range': (1, 2), 'vectorizer__min_df': 1, 'vectorizer__max_features': None, 'vectorizer__max_df': 0.3, 'vectorizer__binary': True, 'classifier__C': 10.0}\n",
      "Best cross-validation accuracy: 0.80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      comedy       0.81      0.71      0.75       875\n",
      "       drama       0.80      0.88      0.84      1194\n",
      "\n",
      "    accuracy                           0.81      2069\n",
      "   macro avg       0.81      0.79      0.80      2069\n",
      "weighted avg       0.81      0.81      0.80      2069\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "# Carrega o dataset\n",
    "df = pd.read_csv(\n",
    "    'https://raw.githubusercontent.com/tiagoft/NLP/main/wiki_movie_plots_drama_comedy.csv'\n",
    ")\n",
    "\n",
    "# Divide os dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['Plot'], df['Genre'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Define o pipeline com TfidfVectorizer e Logistic Regression\n",
    "model_lr = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Define o grid de hiperparâmetros (mesmo grid, mas a busca será aleatória)\n",
    "param_grid = {\n",
    "    'vectorizer__stop_words': [None, 'english'],\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2)],\n",
    "    'vectorizer__max_features': [None, 5000, 10000],\n",
    "    'vectorizer__min_df': [1, 5, 0.01],\n",
    "    'vectorizer__max_df': [1.0, 0.9, 0.3],\n",
    "    'vectorizer__binary': [True, False],\n",
    "    'classifier__C': [1e-1, 1e0, 1e1],\n",
    "}\n",
    "\n",
    "# Configura o RandomizedSearchCV com um número fixo de iterações\n",
    "random_search = RandomizedSearchCV(\n",
    "    model_lr,\n",
    "    param_grid,\n",
    "    cv=5,              # Você pode diminuir para cv=3 se quiser reduzir ainda mais o tempo\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    n_iter=50,         # Número de combinações a serem testadas\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Executa a busca\n",
    "random_search.fit(X_train, y_train)\n",
    "print(f'Best parameters: {random_search.best_params_}')\n",
    "print(f'Best cross-validation accuracy: {random_search.best_score_:.2f}')\n",
    "\n",
    "y_pred = random_search.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f2f2f2; color: #000;\">\n",
    "# Explicação dos Resultados\n",
    "\n",
    "## Melhores Hiperparâmetros Encontrados\n",
    "- **vectorizer__stop_words: 'english'**  \n",
    "  Remove palavras comuns em inglês (stop words) que podem não ser úteis para a classificação.\n",
    "\n",
    "- **vectorizer__ngram_range: (1, 2)**  \n",
    "  Utiliza tanto unigrams (palavras isoladas) quanto bigrams (pares de palavras), permitindo ao modelo capturar relações e contextos melhorados.\n",
    "\n",
    "- **vectorizer__min_df: 1**  \n",
    "  Inclui termos que aparecem em pelo menos 1 documento, garantindo que nenhum termo potencialmente informativo seja descartado.\n",
    "\n",
    "- **vectorizer__max_features: None**  \n",
    "  Não limita o número de características extraídas, usando todas as que passam pelos filtros aplicados.\n",
    "\n",
    "- **vectorizer__max_df: 0.3**  \n",
    "  Exclui termos que aparecem em mais de 30% dos documentos, removendo palavras muito frequentes que podem não ter poder discriminativo.\n",
    "\n",
    "- **vectorizer__binary: True**  \n",
    "  Converte as frequências dos termos em valores binários (0 ou 1), indicando apenas a presença ou ausência dos termos, o que pode ser útil quando a frequência não acrescenta muita informação.\n",
    "\n",
    "- **classifier__C: 10.0**  \n",
    "  Define a força da regularização na regressão logística. Um valor maior reduz a regularização, permitindo que o modelo se ajuste mais aos dados de treinamento.\n",
    "\n",
    "## Desempenho na Validação Cruzada\n",
    "- **Acurácia Média: 0.80**  \n",
    "  Durante a validação cruzada, o modelo acertou aproximadamente 80% das predições, indicando uma performance consistente nos diferentes folds.\n",
    "\n",
    "## Relatório de Classificação no Conjunto de Teste\n",
    "| Classe  | Precisão | Recall | F1-Score | Suporte |\n",
    "|---------|----------|--------|----------|---------|\n",
    "| comedy  | 0.81     | 0.71   | 0.75     | 875     |\n",
    "| drama   | 0.80     | 0.88   | 0.84     | 1194    |\n",
    "\n",
    "### Interpretação dos Indicadores\n",
    "- **Precisão (Precision):**\n",
    "  - **Comedy:** Quando o modelo previu \"comedy\", 81% das vezes estava correto.\n",
    "  - **Drama:** Quando o modelo previu \"drama\", 80% das vezes estava correto.\n",
    "\n",
    "- **Recall (Sensibilidade):**\n",
    "  - **Comedy:** O modelo identificou corretamente 71% de todos os casos reais de comédia.\n",
    "  - **Drama:** O modelo identificou corretamente 88% de todos os casos reais de drama.\n",
    "\n",
    "- **F1-Score:**\n",
    "  - Combina precisão e recall em uma única métrica.  \n",
    "  - **Comedy:** 0.75  \n",
    "  - **Drama:** 0.84  \n",
    "  Valores mais altos indicam um equilíbrio melhor entre precisão e recall.\n",
    "\n",
    "- **Suporte:**\n",
    "  - Número de amostras reais para cada classe no conjunto de teste.\n",
    "  - **Comedy:** 875 amostras  \n",
    "  - **Drama:** 1194 amostras\n",
    "\n",
    "- **Acurácia Geral: 0.81**\n",
    "  - O modelo acertou 81% das predições no conjunto de teste.\n",
    "\n",
    "- **Macro Avg vs. Weighted Avg:**\n",
    "  - **Macro avg:** Média simples dos indicadores de cada classe, tratando todas as classes igualmente.\n",
    "  - **Weighted avg:** Média ponderada pelo número de amostras (suporte) de cada classe, refletindo a distribuição real das classes.\n",
    "\n",
    "## Considerações Finais\n",
    "- **Performance Geral:**  \n",
    "  O modelo apresenta uma boa capacidade de generalização, com uma acurácia de aproximadamente 80-81% tanto na validação cruzada quanto no teste.\n",
    "\n",
    "- **Ajuste dos Hiperparâmetros:**  \n",
    "  A escolha dos melhores hiperparâmetros indica que:\n",
    "  - A remoção de stop words e a inclusão de bigrams contribuem positivamente para a classificação.\n",
    "  - O uso de `max_df=0.3` ajuda a eliminar termos muito frequentes que podem ser irrelevantes.\n",
    "  - A configuração binária para a presença de termos pode estar simplificando a representação dos textos de forma eficaz.\n",
    "  - Um valor mais alto para `C` (10.0) sugere que um modelo menos regularizado se ajusta melhor aos dados disponíveis.\n",
    "\n",
    "- **Desempenho Diferenciado entre Classes:**  \n",
    "  Observa-se que o modelo tem um recall mais alto para a classe \"drama\" (88%) do que para \"comedy\" (71%), o que pode indicar que o modelo é mais sensível ou que há características dos textos de drama que facilitam sua identificação.\n",
    "\n",
    "Em resumo, os resultados indicam que, com os hiperparâmetros otimizados, o modelo consegue classificar bem os plots de filmes em comédia e drama, atingindo um bom equilíbrio entre precisão e recall, especialmente para a classe \"drama\".\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6: how much data we need?\n",
    "\n",
    "At this point, you should be comfortable with the idea that a classifier has an *accuracy*. We have studied that accuracies can vary a bit when we reshuffle data, and that changing the data representation or the model can have some impact on the accuracy. Today, we are going to take a look at the dataset.\n",
    "\n",
    "### An upper bound for classification accuracy\n",
    "\n",
    "Remember that a classifier calculates $p_j = P(\\text{class} = c_j | \\text{features})$ for each class $c_j$ and then yiels the label of the class with higher probability. We know that using too few data points can lead to a poor estimation of $p_j$, but let's focus on this ideal scenario in which we have an infinite amount of data and our probability estimators are completely fit.\n",
    "\n",
    "We could have, for example, $p_0=0.8$ and $p_1=0.2$. In this case, the classifier would indicate that the correct class is $c_0$. However, there is still a $0.2$ probability that the correct class is $c_1$. In other words, this perfectly adjusted classifier, even if perfectly modelling the true distribution of data, is still going to be wrong $20\\%$ of the time.\n",
    "\n",
    "For most features, this upper bound for accuracy exists - even if we don't reach it. This is called a Bayes limit, as it is an upper bound for the accuracy of classifiers based on the posterior probabilities.\n",
    "\n",
    "### Overfitting and avoiding overfitting\n",
    "\n",
    "Suppose we have only fitted our classifier with one data item. In this case, the classifier is perfectly adjusted for that one item. Hence, the classification accuracy for that one item is $1.0$. However, its parameters are not meaningful for any other data points. This phenomenon is called \"overfitting\".\n",
    "\n",
    "As we increase the size of the training set, the adjustments are made towards representative aspects of the dataset. For larger datasets, the representative aspects are not necessarily representative of each data item. This is similar to an estimation of, for example, a mean value. We can get the mean height for students in our classroom, and this estimate would be more precise as we increase the number of students used for calculating that mean. However, as we increase this number (which is our \"training dataset size\"), there is a higher probability that the mean is not representative of *each one* of the students in the training set.\n",
    "\n",
    "As a consequence, the accuracy in the training set tends to decrease as the training dataset increases. But, will it decrease forever? Well, we know that it should go down to the Bayes limit we discussed above, but it doesn't make sense to expect it to go much below it.\n",
    "\n",
    "Conversely, as the training dataset increases in size, the classification accuracy in the testing set increases, as the model estimate gets closer to \"reality\".\n",
    "\n",
    "### How does that happen in practice?\n",
    "\n",
    "Sklearn can help us viewing a training curve. Let's check and take a look at how to interpret it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model_lr = Pipeline([('vectorizer', TfidfVectorizer(stop_words='english')),\n",
    "                     ('classifier', LogisticRegression())])\n",
    "\n",
    "# Define the training sizes\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    model_lr,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
    ")\n",
    "\n",
    "# Calculate the mean and standard deviation for training and test scores\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = 2*np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = 2*np.std(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the learning curve\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.title(\"Learning Curve for Logistic Regression Model\")\n",
    "plt.xlabel(\"Training examples\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.grid()\n",
    "\n",
    "# Plot the training scores\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                 color=\"r\")\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "         label=\"Training score\")\n",
    "\n",
    "# Plot the cross-validation scores\n",
    "plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "         label=\"Test score\")\n",
    "# plt.semilogx()\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, go back to the learning curve plot.\n",
    "\n",
    "1. Why is there some variance in the scores around each point?\n",
    "1. Is the curve closer to linear when you uncomment the line `plt.semilogx`?\n",
    "1. What happens to the test accuracy each time we double the amount of training samples?\n",
    "1. If we had an infinite amount of data, what would be the accuracy of our system (make a polite guess using the curves!)\n",
    "1. Could we get 95% accuracy with this model in this dataset, if the dataset was increased?\n",
    "\n",
    "To learn more about learning curves, refer to:\n",
    "\n",
    "* [Learning curves: Asymptotic values and rate of convergence (Cortes, ackel, Solla, Vapnik and Denker), Proc. of NIPS 1993](https://papers.nips.cc/paper_files/paper/1993/hash/1aa48fc4880bb0c9b8a3bf979d3b917e-Abstract.html).\n",
    "* [How Much More Data Do I Need? Estimating Requirements for Downstream Tasks (Mahmood et al.), Proc. of CVPR 2022](https://arxiv.org/pdf/2207.01725)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Enunciado:\n",
    "    Com base na curva de aprendizado gerada para o modelo de regressão logística, responda:\n",
    "        1.\tPor que há alguma variância nas pontuações em cada ponto?\n",
    "        2.\tA curva fica mais linear quando se usa plt.semilogx?\n",
    "        3.\tO que acontece com a acurácia de teste a cada vez que dobramos a quantidade de amostras de treinamento?\n",
    "        4.\tSe tivéssemos uma quantidade infinita de dados, qual seria, de forma educada, a acurácia do sistema (utilizando a curva como guia)?\n",
    "        5.\tSeria possível obter 95% de acurácia com esse modelo neste dataset, se aumentássemos o tamanho do conjunto de dados?\n",
    "\n",
    "    ⸻\n",
    "\n",
    "    Contextualização:\n",
    "    A curva de aprendizado mostra a evolução da performance do modelo (tanto no conjunto de treinamento quanto no de teste) conforme aumentamos a quantidade de dados para treino. Essa ferramenta nos ajuda a identificar se o modelo está sofrendo de overfitting ou underfitting, além de nos dar uma ideia do limite superior de performance (o chamado limite de Bayes), que representa a máxima acurácia possível mesmo com estimadores perfeitos.\n",
    "\n",
    "    ⸻\n",
    "\n",
    "    Resolução Detalhada:\n",
    "        1.\tVariância nas Pontuações:\n",
    "        •\tMotivo: A variância em cada ponto ocorre porque, durante a validação cruzada, o conjunto de treinamento é dividido em vários “folds”. Cada divisão aleatória pode resultar em uma ligeira variação nos dados de treino e validação, causando flutuações nas pontuações.\n",
    "        •\tResumo: A variação reflete a instabilidade inerente às diferentes divisões dos dados.\n",
    "        2.\tUso do plt.semilogx:\n",
    "        •\tMotivo: Quando usamos uma escala logarítmica no eixo x, que representa o número de exemplos de treinamento, a taxa de crescimento dos dados (muitas vezes exponencial) é “achatada”, o que pode fazer com que a curva de aprendizado pareça mais linear.\n",
    "        •\tResumo: Sim, a curva tende a parecer mais linear com plt.semilogx porque a escala logarítmica normaliza a distribuição dos tamanhos de treinamento.\n",
    "        3.\tEfeito de Dobrar a Quantidade de Dados:\n",
    "        •\tObservação: A cada vez que dobramos o número de amostras, o modelo geralmente consegue capturar melhor as características representativas do dataset, aumentando a acurácia de teste.\n",
    "        •\tLimitação: Contudo, esse ganho tende a ser decrescente – os incrementos na acurácia vão diminuindo à medida que se aproxima do limite superior (o limite de Bayes).\n",
    "        •\tResumo: Dobrar os dados geralmente melhora a acurácia de teste, mas com retornos decrescentes; o aumento não é linear.\n",
    "        4.\tAcurácia com Dados Infinitos:\n",
    "        •\tEstimativa: Com uma quantidade infinita de dados, o modelo se aproximaria do limite de Bayes, ou seja, da acurácia máxima que é inerente à separabilidade dos dados.\n",
    "        •\tObservação da Curva: Se a curva de teste se estabiliza, por exemplo, próximo de 80%, esse é um indicativo de que esse pode ser o limite superior atingível com a representação e o modelo atuais.\n",
    "        •\tResumo: De maneira educada, diríamos que a acurácia se estabilizaria próximo a ~80%, refletindo o limite imposto pela qualidade dos dados e pela tarefa.\n",
    "        5.\tPossibilidade de 95% de Acurácia:\n",
    "        •\tRaciocínio: Se o limite teórico (ou de Bayes) para o dataset é em torno de 80%, mesmo com um aumento massivo de dados, o modelo não poderá ultrapassar esse teto, pois há ruído e sobreposição inerentes às classes.\n",
    "        •\tConclusão: Obter 95% de acurácia com esse modelo neste dataset é improvável, pois os dados não permitem uma separação tão limpa entre as classes.\n",
    "\n",
    "    ⸻\n",
    "\n",
    "    Conclusão Objetiva:\n",
    "        1.\tVariância: A variância nas pontuações resulta das diferentes divisões dos dados na validação cruzada.\n",
    "        2.\tEscala Logarítmica: Sim, usar plt.semilogx pode fazer a curva parecer mais linear, normalizando a escala dos exemplos de treinamento.\n",
    "        3.\tDobrar Dados: Cada vez que dobramos a quantidade de dados, a acurácia de teste aumenta, mas os ganhos são decrescentes à medida que se aproxima do limite máximo.\n",
    "        4.\tDados Infinitos: Com dados infinitos, a acurácia se estabilizaria próximo ao limite de Bayes – no exemplo, aproximadamente 80%.\n",
    "        5.\t95% de Acurácia: Atingir 95% de acurácia é improvável, pois o limite de desempenho imposto pela natureza dos dados parece estar muito abaixo desse valor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f2f2f2; color: #000;\">\n",
    "\n",
    "# Overfitting e Underfitting\n",
    "\n",
    "## Overfitting\n",
    "Overfitting ocorre quando o modelo se ajusta demais aos dados de treinamento, capturando não apenas os padrões reais, mas também o ruído e as flutuações aleatórias. Isso resulta em um modelo que apresenta excelente desempenho nos dados de treinamento, mas falha em generalizar para novos dados, levando a um desempenho ruim em testes ou em produção.\n",
    "\n",
    "### Sinais de Overfitting\n",
    "- **Desempenho discrepante:** Alta acurácia no conjunto de treinamento e baixa acurácia no conjunto de validação/teste.\n",
    "- **Complexidade excessiva:** Modelo com muitos parâmetros ou uma arquitetura muito complexa para a quantidade de dados disponível.\n",
    "- **Curvas de erro divergentes:** A curva de erro do treinamento continua a diminuir, enquanto a de validação começa a aumentar após certo ponto.\n",
    "\n",
    "### Estratégias para Mitigar o Overfitting\n",
    "- **Regularização:** Aplicar técnicas como L1, L2 ou dropout para penalizar a complexidade do modelo.\n",
    "- **Aumento de dados (Data Augmentation):** Expandir o conjunto de treinamento com variações dos dados originais.\n",
    "- **Simplificar o modelo:** Reduzir o número de parâmetros ou usar um modelo menos complexo.\n",
    "- **Validação cruzada:** Utilizar técnicas que ajudam a monitorar o desempenho do modelo em dados não vistos durante o treinamento.\n",
    "\n",
    "## Underfitting\n",
    "Underfitting ocorre quando o modelo é simples demais para capturar os padrões subjacentes dos dados. Nesse caso, o modelo não consegue ajustar bem nem os dados de treinamento, resultando em um desempenho ruim tanto no treinamento quanto na validação/teste.\n",
    "\n",
    "### Sinais de Underfitting\n",
    "- **Baixo desempenho geral:** Desempenho insatisfatório nos conjuntos de treinamento e teste.\n",
    "- **Modelo simples demais:** Poucos parâmetros ou uma estrutura que não é capaz de capturar a complexidade dos dados.\n",
    "- **Curva de erro elevada:** Tanto a curva de treinamento quanto a de validação permanecem altas e não mostram melhora significativa.\n",
    "\n",
    "### Estratégias para Combater o Underfitting\n",
    "- **Aumentar a complexidade do modelo:** Adicionar mais parâmetros ou usar arquiteturas mais sofisticadas.\n",
    "- **Melhorar a extração de features:** Utilizar técnicas de engenharia de features ou modelos que capturam melhor as características dos dados.\n",
    "- **Treinamento mais prolongado:** Permitir que o modelo tenha mais tempo e iterações para aprender os padrões dos dados.\n",
    "\n",
    "## Resumo\n",
    "- **Overfitting:** Modelo muito complexo que aprende ruídos dos dados de treinamento, prejudicando a generalização.\n",
    "- **Underfitting:** Modelo muito simples que não consegue capturar os padrões dos dados, resultando em desempenho ruim em todos os conjuntos.\n",
    "\n",
    "Compreender e equilibrar esses dois aspectos é fundamental para desenvolver modelos que sejam ao mesmo tempo precisos e capazes de generalizar para novos dados.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7: Other Machine Learning Algorithms and Ensembles\n",
    "\n",
    "If you have taken other Machine Learning courses, or if you have studied Machine Learning in other contexts, you might be aware that there are many algorithms that are able to learn from data. Each of these algorithms stems from a different rationale.\n",
    "\n",
    "We can run all tests above with different model pipeline configurations, which could be important. I will leave this laborious task as an optional exercise, because it consists of changing one or two lines in each block and then running everything again (at this point, we don't want to show that one strategy is necessarily \"better\" than another).\n",
    "\n",
    "Instead, I want to discuss ensembles. The idea of an ensemble is to have many classifiers operating in parallel, and then combining their results. The rationale for this is that, supposably, if one model is \"wrong\", there is a chance that the other models are \"right\", so the combined model would be correct more times (on average).\n",
    "\n",
    "There are many strategies to \"combine results\". The simplest one is to have each classifier to classify an item, and then use simple voting to find the final classification of that item. It is also possible to use a (possible weighted) mean of the predicted probabilities for each model. Also, it is possible to use the outputs of the classifiers as a large \"feature vector\" and then use another classifier (a so-called meta-classifier) to make a final decision.\n",
    "\n",
    "Below, there is an example code showing how to combine many classifiers into a voting ensemble.\n",
    "\n",
    "1. Add at least two other classifiers to the ensemble. Read sklearn's documentation for such.\n",
    "1. Using a bar plot (see code below), compare the accuracy and the f1-score of the ensemble and of each isolated classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "classifier = VotingClassifier([('lr', LogisticRegression()),\n",
    "                               ('rf', RandomForestClassifier()),\n",
    "                               ('nb', BernoulliNB())])\n",
    "\n",
    "model_ensemble = Pipeline([('vectorizer',\n",
    "                      TfidfVectorizer(\n",
    "                          stop_words='english', # remove stopwords, ou seja, palavras comuns que não agregam muito significado\n",
    "                          binary=True, # binarize the counts, ou seja, 0 ou 1\n",
    "                      )), ('classifier', classifier)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded. Training model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;,\n",
       "                 TfidfVectorizer(binary=True, stop_words=&#x27;english&#x27;)),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 VotingClassifier(estimators=[(&#x27;lr&#x27;, LogisticRegression()),\n",
       "                                              (&#x27;rf&#x27;, RandomForestClassifier()),\n",
       "                                              (&#x27;nb&#x27;, BernoulliNB())]))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;,\n",
       "                 TfidfVectorizer(binary=True, stop_words=&#x27;english&#x27;)),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 VotingClassifier(estimators=[(&#x27;lr&#x27;, LogisticRegression()),\n",
       "                                              (&#x27;rf&#x27;, RandomForestClassifier()),\n",
       "                                              (&#x27;nb&#x27;, BernoulliNB())]))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TfidfVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer(binary=True, stop_words=&#x27;english&#x27;)</pre></div> </div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>classifier: VotingClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.VotingClassifier.html\">?<span>Documentation for classifier: VotingClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>VotingClassifier(estimators=[(&#x27;lr&#x27;, LogisticRegression()),\n",
       "                             (&#x27;rf&#x27;, RandomForestClassifier()),\n",
       "                             (&#x27;nb&#x27;, BernoulliNB())])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>lr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>nb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>BernoulliNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.naive_bayes.BernoulliNB.html\">?<span>Documentation for BernoulliNB</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>BernoulliNB()</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vectorizer',\n",
       "                 TfidfVectorizer(binary=True, stop_words='english')),\n",
       "                ('classifier',\n",
       "                 VotingClassifier(estimators=[('lr', LogisticRegression()),\n",
       "                                              ('rf', RandomForestClassifier()),\n",
       "                                              ('nb', BernoulliNB())]))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/tiagoft/NLP/main/wiki_movie_plots_drama_comedy.csv')\n",
    "print('Data loaded. Training model...')\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Plot'], df['Genre'], test_size=0.2)\n",
    "# Train the pipeline\n",
    "model_ensemble.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.78\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_ensemble.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "# - Sort bars by accuracy\n",
    "# - Use a different color for the model we want to highlight (possibly our proposal, or, in this case, the ensemble)\n",
    "plt.bar(['model 1', 'model 2', 'model 3', 'ensemble'], [0.6, 0.7, 0.9, 0.92], color=['blue', 'blue', 'blue', 'red'])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel('Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    #Enunciado:\n",
    "    Adicionar pelo menos dois classificadores extras a um ensemble e comparar a acurácia e o F1-score de cada classificador isolado e do ensemble, exibindo os resultados em um gráfico de barras.\n",
    "\n",
    "    ⸻\n",
    "\n",
    "    1. Adicionando outros Classificadores\n",
    "\n",
    "    A ideia do ensemble (voting ensemble) é combinar vários modelos e usar o voto (ou a média das probabilidades) para obter a predição final. No exemplo fornecido, já temos:\n",
    "        •\tLogisticRegression()\n",
    "        •\tRandomForestClassifier()\n",
    "        •\tBernoulliNB()\n",
    "\n",
    "    Vamos adicionar pelo menos dois outros classificadores. Por exemplo:\n",
    "        1.\tSVC (Suport Vector Classifier)\n",
    "        2.\tDecisionTreeClassifier\n",
    "\n",
    "    Isso nos dará um ensemble com 5 classificadores.\n",
    "\n",
    "    ⸻\n",
    "\n",
    "    2. Comparando Desempenho de Cada Modelo Isolado vs. Ensemble\n",
    "\n",
    "    Para comparar, treinaremos individualmente cada classificador (usando o mesmo TfidfVectorizer) e mediremos:\n",
    "        •\tAccuracy\n",
    "        •\tF1-score\n",
    "\n",
    "    Depois, treinaremos o ensemble que combina todos eles e calcularemos as mesmas métricas.\n",
    "\n",
    "    ⸻\n",
    "\n",
    "    3. Exemplo de Código\n",
    "\n",
    "    Abaixo, segue um código ilustrativo que:\n",
    "        1.\tLê o dataset.\n",
    "        2.\tCria um pipeline para cada classificador individual (transformação TF-IDF + modelo).\n",
    "        3.\tCria um pipeline para o ensemble (transformação TF-IDF + VotingClassifier).\n",
    "        4.\tTreina todos os modelos no conjunto de treinamento e avalia no conjunto de teste.\n",
    "        5.\tColeta accuracy e f1-score de cada modelo.\n",
    "        6.\tPlota um gráfico de barras comparando os valores obtidos.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 1. Carrega o dataset\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/tiagoft/NLP/main/wiki_movie_plots_drama_comedy.csv')\n",
    "\n",
    "# Divide em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Plot'], df['Genre'], test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. Cria pipelines para cada classificador\n",
    "pipelines = {\n",
    "    'LogisticRegression': Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(stop_words='english', binary=True)),\n",
    "        ('clf', LogisticRegression())\n",
    "    ]),\n",
    "    'RandomForest': Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(stop_words='english', binary=True)),\n",
    "        ('clf', RandomForestClassifier())\n",
    "    ]),\n",
    "    'NaiveBayes': Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(stop_words='english', binary=True)),\n",
    "        ('clf', BernoulliNB())\n",
    "    ]),\n",
    "    'SVC': Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(stop_words='english', binary=True)),\n",
    "        ('clf', SVC(probability=True))  # probabilidade=True para permitir voting por probabilidade, se desejado\n",
    "    ]),\n",
    "    'DecisionTree': Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(stop_words='english', binary=True)),\n",
    "        ('clf', DecisionTreeClassifier())\n",
    "    ])\n",
    "}\n",
    "\n",
    "# 3. Cria o ensemble\n",
    "#   Observação: VotingClassifier requer uma lista de tuplas (nome, estimador)\n",
    "ensemble_classifier = VotingClassifier([\n",
    "    ('lr', LogisticRegression()),\n",
    "    ('rf', RandomForestClassifier()),\n",
    "    ('nb', BernoulliNB()),\n",
    "    ('svc', SVC(probability=True)),\n",
    "    ('dt', DecisionTreeClassifier())\n",
    "], voting='hard')  # ou 'soft' para votar por probabilidade\n",
    "\n",
    "model_ensemble = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english', binary=True)),\n",
    "    ('ensemble', ensemble_classifier)\n",
    "])\n",
    "\n",
    "# 4. Treina todos os pipelines e coleta métricas\n",
    "model_names = []\n",
    "accuracies = []\n",
    "f1_scores = []\n",
    "\n",
    "for name, pipe in pipelines.items():\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    model_names.append(name)\n",
    "    accuracies.append(acc)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Treina o ensemble\n",
    "model_ensemble.fit(X_train, y_train)\n",
    "y_pred_ensemble = model_ensemble.predict(X_test)\n",
    "acc_ensemble = accuracy_score(y_test, y_pred_ensemble)\n",
    "f1_ensemble = f1_score(y_test, y_pred_ensemble, average='macro')\n",
    "\n",
    "model_names.append('Ensemble')\n",
    "accuracies.append(acc_ensemble)\n",
    "f1_scores.append(f1_ensemble)\n",
    "\n",
    "# 5. Plotando gráfico comparativo\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "# Gráfico de acurácia\n",
    "plt.subplot(1, 2, 1)\n",
    "colors = ['blue'] * (len(model_names) - 1) + ['red']  # Último será o ensemble\n",
    "plt.bar(model_names, accuracies, color=colors)\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Comparison')\n",
    "\n",
    "# Gráfico de F1-score\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(model_names, f1_scores, color=colors)\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel('F1-score')\n",
    "plt.title('F1-score Comparison')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Impressão dos resultados numéricos\n",
    "for i, name in enumerate(model_names):\n",
    "    print(f'{name}: Accuracy={accuracies[i]:.2f}, F1={f1_scores[i]:.2f}')\n",
    "````\n",
    "\n",
    "    Observações Importantes\n",
    "        1.\tVoting por “hard” ou “soft”\n",
    "        •\tvoting='hard' faz o voto majoritário do rótulo predito.\n",
    "        •\tvoting='soft' faz a média (ou soma) das probabilidades, o que exige que todos os classificadores tenham a opção probability=True (no caso do SVC) ou, no caso de classificadores como RandomForest e LogisticRegression, que naturalmente já preveem probabilidades.\n",
    "        2.\tEscolha de Classificadores\n",
    "        •\tOs classificadores escolhidos (LogisticRegression, RandomForest, BernoulliNB, SVC, DecisionTree) são apenas exemplos. Você pode adicionar ou remover classificadores de acordo com seu interesse (ex.: KNeighborsClassifier, GradientBoostingClassifier, etc.).\n",
    "        3.\tDesempenho e Tempo de Treinamento\n",
    "        •\tIncluir vários modelos em um ensemble pode aumentar o custo computacional, principalmente com algoritmos mais pesados (por exemplo, RandomForest com muitos estimadores).\n",
    "\n",
    "    ⸻\n",
    "\n",
    "    Conclusão\n",
    "        •\tEnsemble: Ao combinar múltiplos modelos, esperamos que o sistema corrija os erros de cada classificador individual, resultando em melhor performance global.\n",
    "        •\tComparação: É fundamental avaliar tanto a acurácia quanto o F1-score (e outras métricas, se necessário) para ter uma visão mais completa do desempenho.\n",
    "        •\tResultado: Geralmente, o ensemble apresenta desempenho igual ou superior ao dos classificadores individuais, mas isso depende da complementaridade dos modelos e do tipo de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: Accuracy=0.79, F1=0.78\n",
      "RandomForest: Accuracy=0.73, F1=0.69\n",
      "NaiveBayes: Accuracy=0.73, F1=0.71\n",
      "SVC: Accuracy=0.79, F1=0.78\n",
      "DecisionTree: Accuracy=0.62, F1=0.60\n",
      "Ensemble: Accuracy=0.78, F1=0.77\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 1. Carrega o dataset\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/tiagoft/NLP/main/wiki_movie_plots_drama_comedy.csv')\n",
    "\n",
    "# Divide em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Plot'], df['Genre'], test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. Cria pipelines para cada classificador\n",
    "pipelines = {\n",
    "    'LogisticRegression': Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(stop_words='english', binary=True)),\n",
    "        ('clf', LogisticRegression())\n",
    "    ]),\n",
    "    'RandomForest': Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(stop_words='english', binary=True)),\n",
    "        ('clf', RandomForestClassifier())\n",
    "    ]),\n",
    "    'NaiveBayes': Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(stop_words='english', binary=True)),\n",
    "        ('clf', BernoulliNB())\n",
    "    ]),\n",
    "    'SVC': Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(stop_words='english', binary=True)),\n",
    "        ('clf', SVC(probability=True))  # probabilidade=True para permitir voting por probabilidade, se desejado\n",
    "    ]),\n",
    "    'DecisionTree': Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(stop_words='english', binary=True)),\n",
    "        ('clf', DecisionTreeClassifier())\n",
    "    ])\n",
    "}\n",
    "\n",
    "# 3. Cria o ensemble\n",
    "#   Observação: VotingClassifier requer uma lista de tuplas (nome, estimador)\n",
    "ensemble_classifier = VotingClassifier([\n",
    "    ('lr', LogisticRegression()),\n",
    "    ('rf', RandomForestClassifier()),\n",
    "    ('nb', BernoulliNB()),\n",
    "    ('svc', SVC(probability=True)),\n",
    "    ('dt', DecisionTreeClassifier())\n",
    "], voting='hard')  # ou 'soft' para votar por probabilidade\n",
    "\n",
    "model_ensemble = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english', binary=True)),\n",
    "    ('ensemble', ensemble_classifier)\n",
    "])\n",
    "\n",
    "# 4. Treina todos os pipelines e coleta métricas\n",
    "model_names = []\n",
    "accuracies = []\n",
    "f1_scores = []\n",
    "\n",
    "for name, pipe in pipelines.items():\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    model_names.append(name)\n",
    "    accuracies.append(acc)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Treina o ensemble\n",
    "model_ensemble.fit(X_train, y_train)\n",
    "y_pred_ensemble = model_ensemble.predict(X_test)\n",
    "acc_ensemble = accuracy_score(y_test, y_pred_ensemble)\n",
    "f1_ensemble = f1_score(y_test, y_pred_ensemble, average='macro')\n",
    "\n",
    "model_names.append('Ensemble')\n",
    "accuracies.append(acc_ensemble)\n",
    "f1_scores.append(f1_ensemble)\n",
    "\n",
    "# 5. Plotando gráfico comparativo\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "# Gráfico de acurácia\n",
    "plt.subplot(1, 2, 1)\n",
    "colors = ['blue'] * (len(model_names) - 1) + ['red']  # Último será o ensemble\n",
    "plt.bar(model_names, accuracies, color=colors)\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Comparison')\n",
    "\n",
    "# Gráfico de F1-score\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(model_names, f1_scores, color=colors)\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel('F1-score')\n",
    "plt.title('F1-score Comparison')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Impressão dos resultados numéricos\n",
    "for i, name in enumerate(model_names):\n",
    "    print(f'{name}: Accuracy={accuracies[i]:.2f}, F1={f1_scores[i]:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Interpretação dos Resultados\n",
    "\n",
    "    Observando os valores de Accuracy e F1-score para cada modelo, temos:\n",
    "        •\tLogisticRegression e SVC apresentam as melhores métricas gerais, ambos com Accuracy de aproximadamente 0.79 e F1-score de 0.78.\n",
    "        •\tRandomForest e NaiveBayes têm desempenhos intermediários, com Accuracy em torno de 0.73. Contudo, a NaiveBayes atinge um F1-score um pouco superior à RandomForest (0.71 vs. 0.69).\n",
    "        •\tDecisionTree obteve o menor desempenho entre todos, com Accuracy de 0.62 e F1-score de 0.60.\n",
    "        •\tO Ensemble (VotingClassifier) ficou ligeiramente abaixo de LogisticRegression e SVC, atingindo Accuracy de 0.78 e F1-score de 0.77. Embora não tenha superado os melhores modelos individuais, apresenta resultados próximos.\n",
    "\n",
    "    Comentários\n",
    "        1.\tModelos que se destacaram: LogisticRegression e SVC tiveram desempenhos muito similares e lideram tanto em Accuracy quanto em F1-score. Isso indica que ambas as abordagens conseguem capturar bem os padrões do texto para distinguir entre os gêneros (Drama e Comédia).\n",
    "        2.\tModelos intermediários: RandomForest e NaiveBayes apresentaram resultados razoáveis, mas não superaram as duas melhores abordagens. A RandomForest muitas vezes requer ajustes nos hiperparâmetros (número de árvores, profundidade, etc.) para melhorar seu desempenho. Já o NaiveBayes costuma ser uma boa escolha para classificação de texto, pois lida bem com dados esparsos e de alta dimensionalidade.\n",
    "        3.\tDecisionTree isolada: Obteve a menor taxa de acerto. Árvores de decisão únicas podem ter dificuldades com dados complexos, mas podem servir de base para métodos de ensemble como RandomForest.\n",
    "        4.\tEnsemble: A estratégia de votação (VotingClassifier) combinou os modelos LogisticRegression, RandomForest, NaiveBayes, SVC e DecisionTree. Apesar de muitas vezes gerar melhoria no desempenho, aqui o ensemble não superou significativamente os melhores modelos individuais (LogisticRegression e SVC). Isso pode ocorrer por diversos fatores, como:\n",
    "        •\tForma de votação (hard vs. soft);\n",
    "        •\tPesos iguais para todos os modelos;\n",
    "        •\tModelos individuais com performances muito distintas.\n",
    "        5.\tPossíveis aprimoramentos:\n",
    "        •\tAjustar hiperparâmetros de cada modelo antes de criar o ensemble;\n",
    "        •\tTestar diferentes estratégias de votação (soft voting, por exemplo);\n",
    "        •\tExplorar técnicas de feature engineering ou preprocessing mais avançadas (remoção de stopwords, stemming, lemmatization, etc.);\n",
    "        •\tUtilizar outras representações de texto (como Word Embeddings ou embeddings de linguagem pré-treinados).\n",
    "\n",
    "    No geral, a análise mostra que tanto LogisticRegression quanto SVC são modelos robustos para esse conjunto de dados, enquanto o ensemble não se destaca tanto na configuração atual. Ajustes finos podem melhorar o desempenho do ensemble e aproximá-lo ou até mesmo superá-lo em relação aos melhores modelos individuais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# um código mais rápido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    A seguir estão algumas sugestões para tornar o processamento do seu código mais rápido, mantendo o mesmo objetivo e escopo (ou seja, sem alterar a tarefa de classificação e a comparação dos modelos):\n",
    "\n",
    "    ⸻\n",
    "\n",
    "    1. Limitar o vocabulário do TfidfVectorizer\n",
    "\n",
    "    Por padrão, o TfidfVectorizer pode gerar milhares (ou até dezenas de milhares) de atributos, dependendo do tamanho do texto. Isso impacta diretamente no tempo de treino de todos os modelos. Você pode, por exemplo, limitar o número máximo de palavras (max_features) e/ou filtrar palavras muito frequentes (max_df) ou muito raras (min_df). Exemplo:\n",
    "\n",
    "    TfidfVectorizer(\n",
    "        stop_words='english',\n",
    "        binary=True,\n",
    "        max_features=10000,    # limita o número de tokens\n",
    "        max_df=0.95,           # ignora tokens que aparecem em mais de 95% dos documentos\n",
    "        min_df=2               # ignora tokens que aparecem em menos de 2 documentos\n",
    "    )\n",
    "\n",
    "    Esses parâmetros costumam reduzir bastante a dimensionalidade, acelerando o treinamento.\n",
    "\n",
    "    ⸻\n",
    "\n",
    "    2. Paralelizar modelos que suportam n_jobs\n",
    "\n",
    "    Alguns classificadores, como o RandomForestClassifier, podem ser paralelizados via parâmetro n_jobs. Por exemplo, se você tem uma máquina com múltiplos núcleos, pode configurar:\n",
    "\n",
    "    RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "\n",
    "    Definir n_jobs=-1 utiliza todos os núcleos disponíveis, acelerando o treinamento em máquinas multicore.\n",
    "\n",
    "    Da mesma forma, em versões recentes do scikit-learn, LogisticRegression pode receber n_jobs se estiver usando os solvers sag ou saga:\n",
    "\n",
    "    LogisticRegression(solver='saga', n_jobs=-1)\n",
    "\n",
    "    Já o SVC não possui suporte nativo a n_jobs (a não ser que você utilize implementações específicas ou bibliotecas como o scikit-learn-intelex ou joblib.parallel_backend, mas isso é mais avançado).\n",
    "\n",
    "    ⸻\n",
    "\n",
    "    3. Remover probability=True do SVC, se não for necessário\n",
    "\n",
    "    Se você está usando voting='hard' no VotingClassifier, não precisa calcular probabilidades no SVC. Calcular as probabilidades (probability=True) no SVC é mais custoso, pois internamente ele roda um procedimento adicional (Platt scaling) para estimar probabilidades. Se o ensemble não está fazendo soft voting, remover essa opção torna o treino do SVC bem mais rápido:\n",
    "\n",
    "    SVC(probability=False)\n",
    "\n",
    "\n",
    "\n",
    "    ⸻\n",
    "\n",
    "    4. Reduzir a complexidade de alguns modelos\n",
    "        •\tRandomForest: reduzir o número de árvores (n_estimators) ou limitar a profundidade das árvores (max_depth) pode acelerar o treinamento, ainda que às custas de algum desempenho.\n",
    "        •\tDecisionTree: definir max_depth ou outros hiperparâmetros para podar a árvore também ajuda:\n",
    "\n",
    "    DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    "\n",
    "    Isso reduz o risco de overfitting e acelera consideravelmente o processo de treino.\n",
    "\n",
    "    ⸻\n",
    "\n",
    "    5. Evitar recomputar o Tfidf para cada modelo (opcional)\n",
    "\n",
    "    Hoje, você cria um pipeline completo para cada modelo. Embora seja muito prático, faz com que o TfidfVectorizer seja ajustado e transformado repetidas vezes. Uma opção (sem alterar o objetivo) é:\n",
    "        1.\tRealizar uma só vez a transformação TF-IDF do texto.\n",
    "        2.\tArmazenar X_train_tfidf e X_test_tfidf.\n",
    "        3.\tPassar esses dados prontos para cada classificador (sem pipeline) ou usar pipelines mas com TfidfVectorizer fixo.\n",
    "\n",
    "    Exemplo simplificado:\n",
    "\n",
    "    # Ajusta e transforma apenas uma vez\n",
    "    tfidf = TfidfVectorizer(stop_words='english', binary=True, max_features=10000)\n",
    "    X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "    X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "    # Agora treine cada modelo diretamente\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "    # ...\n",
    "\n",
    "    Isso evita recalcular TF-IDF para cada modelo, economizando tempo de processamento.\n",
    "\n",
    "    ⸻\n",
    "\n",
    "    6. Exemplo de código modificado\n",
    "\n",
    "    Abaixo, um trecho que ilustra como aplicar algumas dessas mudanças. Note que não é necessário aplicar todas as sugestões ao mesmo tempo; você pode escolher as que melhor se adequam ao seu cenário:\n",
    "```python\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import accuracy_score, f1_score\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "    from sklearn.naive_bayes import BernoulliNB\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "    # 1. Carrega o dataset\n",
    "    df = pd.read_csv('https://raw.githubusercontent.com/tiagoft/NLP/main/wiki_movie_plots_drama_comedy.csv')\n",
    "\n",
    "    # Divide em treino e teste\n",
    "    X_train, X_test, y_train = ... # seu código de split\n",
    "\n",
    "    # 2. Cria pipelines para cada classificador (com ajustes de performance)\n",
    "    pipelines = {\n",
    "        'LogisticRegression': Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(stop_words='english', binary=True, max_features=10000)),\n",
    "            ('clf', LogisticRegression(solver='saga', n_jobs=-1, random_state=42))\n",
    "        ]),\n",
    "        'RandomForest': Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(stop_words='english', binary=True, max_features=10000)),\n",
    "            ('clf', RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42))\n",
    "        ]),\n",
    "        'NaiveBayes': Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(stop_words='english', binary=True, max_features=10000)),\n",
    "            ('clf', BernoulliNB())\n",
    "        ]),\n",
    "        'SVC': Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(stop_words='english', binary=True, max_features=10000)),\n",
    "            ('clf', SVC(probability=False, random_state=42))  # remove probability se for usar voting='hard'\n",
    "        ]),\n",
    "        'DecisionTree': Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(stop_words='english', binary=True, max_features=10000)),\n",
    "            ('clf', DecisionTreeClassifier(max_depth=10, random_state=42))\n",
    "        ])\n",
    "    }\n",
    "\n",
    "    # 3. Cria o ensemble (voting='hard', sem necessidade de probability=True)\n",
    "    ensemble_classifier = VotingClassifier([\n",
    "        ('lr', LogisticRegression(solver='saga', n_jobs=-1, random_state=42)),\n",
    "        ('rf', RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42)),\n",
    "        ('nb', BernoulliNB()),\n",
    "        ('svc', SVC(probability=False, random_state=42)),\n",
    "        ('dt', DecisionTreeClassifier(max_depth=10, random_state=42))\n",
    "    ], voting='hard')\n",
    "\n",
    "    model_ensemble = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(stop_words='english', binary=True, max_features=10000)),\n",
    "        ('ensemble', ensemble_classifier)\n",
    "    ])\n",
    "\n",
    "    # 4. Treina todos os pipelines e coleta métricas\n",
    "    model_names = []\n",
    "    accuracies = []\n",
    "    f1_scores = []\n",
    "\n",
    "    for name, pipe in pipelines.items():\n",
    "        pipe.fit(X_train, y_train)\n",
    "        y_pred = pipe.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average='macro')\n",
    "        model_names.append(name)\n",
    "        accuracies.append(acc)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    # Treina o ensemble\n",
    "    model_ensemble.fit(X_train, y_train)\n",
    "    y_pred_ensemble = model_ensemble.predict(X_test)\n",
    "    acc_ensemble = accuracy_score(y_test, y_pred_ensemble)\n",
    "    f1_ensemble = f1_score(y_test, y_pred_ensemble, average='macro')\n",
    "\n",
    "    model_names.append('Ensemble')\n",
    "    accuracies.append(acc_ensemble)\n",
    "    f1_scores.append(f1_ensemble)\n",
    "\n",
    "    # 5. Plotando gráfico comparativo (mesmo código)\n",
    "\n",
    "    # ... seu código de plot ...\n",
    "\n",
    "    # Impressão dos resultados\n",
    "    for i, name in enumerate(model_names):\n",
    "        print(f'{name}: Accuracy={accuracies[i]:.2f}, F1={f1_scores[i]:.2f}')\n",
    "\n",
    "```\n",
    "\n",
    "    ⸻\n",
    "\n",
    "    Conclusão\n",
    "\n",
    "    Para acelerar o processamento, foque em:\n",
    "        1.\tReduzir a dimensionalidade do TF-IDF (limitando max_features, usando min_df, max_df etc.).\n",
    "        2.\tParalelizar os classificadores que suportam n_jobs.\n",
    "        3.\tEvitar o cálculo desnecessário de probabilidades no SVC (caso não use soft voting).\n",
    "        4.\tRestringir a complexidade de modelos como RandomForest e DecisionTree.\n",
    "        5.\t(Opcional) Evitar recomputar o TF-IDF para cada modelo se quiser manter apenas uma única transformação de texto.\n",
    "\n",
    "    Esses ajustes geralmente trazem ganhos significativos de performance sem alterar o objetivo principal do código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: Accuracy=0.79, F1=0.78\n",
      "RandomForest: Accuracy=0.74, F1=0.72\n",
      "NaiveBayes: Accuracy=0.74, F1=0.72\n",
      "SVC: Accuracy=0.79, F1=0.78\n",
      "DecisionTree: Accuracy=0.60, F1=0.60\n",
      "Ensemble: Accuracy=0.79, F1=0.78\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 1. Carrega o dataset\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/tiagoft/NLP/main/wiki_movie_plots_drama_comedy.csv')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Supondo que o dataframe tenha colunas 'Plot' e 'Genre'\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['Plot'],\n",
    "    df['Genre'],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 2. Cria pipelines para cada classificador (com ajustes de performance)\n",
    "pipelines = {\n",
    "    'LogisticRegression': Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(stop_words='english', binary=True, max_features=10000)),\n",
    "        ('clf', LogisticRegression(solver='saga', n_jobs=-1, random_state=42))\n",
    "    ]),\n",
    "    'RandomForest': Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(stop_words='english', binary=True, max_features=10000)),\n",
    "        ('clf', RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42))\n",
    "    ]),\n",
    "    'NaiveBayes': Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(stop_words='english', binary=True, max_features=10000)),\n",
    "        ('clf', BernoulliNB())\n",
    "    ]),\n",
    "    'SVC': Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(stop_words='english', binary=True, max_features=10000)),\n",
    "        ('clf', SVC(probability=False, random_state=42))  # remove probability se for usar voting='hard'\n",
    "    ]),\n",
    "    'DecisionTree': Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(stop_words='english', binary=True, max_features=10000)),\n",
    "        ('clf', DecisionTreeClassifier(max_depth=10, random_state=42))\n",
    "    ])\n",
    "}\n",
    "\n",
    "# 3. Cria o ensemble (voting='hard', sem necessidade de probability=True)\n",
    "ensemble_classifier = VotingClassifier([\n",
    "    ('lr', LogisticRegression(solver='saga', n_jobs=-1, random_state=42)),\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42)),\n",
    "    ('nb', BernoulliNB()),\n",
    "    ('svc', SVC(probability=False, random_state=42)),\n",
    "    ('dt', DecisionTreeClassifier(max_depth=10, random_state=42))\n",
    "], voting='hard')\n",
    "\n",
    "model_ensemble = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english', binary=True, max_features=10000)),\n",
    "    ('ensemble', ensemble_classifier)\n",
    "])\n",
    "\n",
    "# 4. Treina todos os pipelines e coleta métricas\n",
    "model_names = []\n",
    "accuracies = []\n",
    "f1_scores = []\n",
    "\n",
    "for name, pipe in pipelines.items():\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    model_names.append(name)\n",
    "    accuracies.append(acc)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Treina o ensemble\n",
    "model_ensemble.fit(X_train, y_train)\n",
    "y_pred_ensemble = model_ensemble.predict(X_test)\n",
    "acc_ensemble = accuracy_score(y_test, y_pred_ensemble)\n",
    "f1_ensemble = f1_score(y_test, y_pred_ensemble, average='macro')\n",
    "\n",
    "model_names.append('Ensemble')\n",
    "accuracies.append(acc_ensemble)\n",
    "f1_scores.append(f1_ensemble)\n",
    "\n",
    "# 5. Plotando gráfico comparativo (mesmo código)\n",
    "\n",
    "# ... seu código de plot ...\n",
    "\n",
    "# Impressão dos resultados\n",
    "for i, name in enumerate(model_names):\n",
    "    print(f'{name}: Accuracy={accuracies[i]:.2f}, F1={f1_scores[i]:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Análise dos Resultados\n",
    "\n",
    "    Os resultados obtidos mostram o desempenho dos diferentes modelos para a tarefa de classificação de gêneros (Drama vs. Comédia) a partir dos plots dos filmes. Segue a análise:\n",
    "\n",
    "    Desempenho Individual dos Modelos\n",
    "        •\tLogisticRegression e SVC\n",
    "        •\tAccuracy: 0.79\n",
    "        •\tF1-score: 0.78\n",
    "    Esses modelos se destacam, alcançando as melhores métricas individuais. Isso indica que ambos são capazes de capturar os padrões presentes nos textos de forma eficaz.\n",
    "        •\tRandomForest e NaiveBayes\n",
    "        •\tAccuracy: 0.74\n",
    "        •\tF1-score: 0.72\n",
    "    Ambos apresentam desempenho intermediário, ligeiramente abaixo dos melhores (LogisticRegression e SVC). O RandomForest pode exigir ajustes adicionais de hiperparâmetros (como número de árvores ou profundidade máxima) para melhorar sua performance. O BernoulliNB, que lida bem com dados esparsos, mostra resultados consistentes, mas não se iguala aos dois melhores.\n",
    "        •\tDecisionTree\n",
    "        •\tAccuracy: 0.60\n",
    "        •\tF1-score: 0.60\n",
    "    O classificador baseado em árvore de decisão, sem técnicas de ensemble, apresenta a pior performance. Isso é esperado, pois árvores de decisão simples tendem a ter dificuldade com a alta dimensionalidade e a complexidade dos dados textuais.\n",
    "\n",
    "    Desempenho do Ensemble\n",
    "        •\tEnsemble (VotingClassifier)\n",
    "        •\tAccuracy: 0.79\n",
    "        •\tF1-score: 0.78\n",
    "    O ensemble combina os modelos individuais por votação majoritária. O fato de ele alcançar métricas iguais aos melhores modelos (LogisticRegression e SVC) indica que a votação conseguiu equilibrar os erros dos modelos menos precisos (como o DecisionTree), mas não proporcionou um ganho significativo em relação aos melhores classificadores isolados.\n",
    "\n",
    "    Considerações Finais\n",
    "        •\tRobustez dos Modelos Individuais:\n",
    "    LogisticRegression e SVC demonstram uma capacidade robusta para lidar com a tarefa de classificação nesse conjunto de dados, possivelmente devido à sua boa generalização em dados de alta dimensionalidade.\n",
    "        •\tValor do Ensemble:\n",
    "    O ensemble, embora não melhore significativamente as métricas dos melhores modelos, oferece uma abordagem que tende a reduzir a variância e pode ser mais estável em cenários com dados ligeiramente diferentes ou ruídos.\n",
    "        •\tPossíveis Ajustes:\n",
    "    Para tentar obter ganhos no ensemble, pode ser interessante ajustar os pesos dos modelos ou explorar estratégias de votação “soft” (quando possível), desde que os modelos possam gerar probabilidades de forma eficiente.\n",
    "\n",
    "    Em resumo, a análise indica que, para esse conjunto de dados, LogisticRegression e SVC são escolhas sólidas, e a combinação via ensemble se iguala a elas, reforçando a robustez desses métodos para classificação de textos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _O que é SVC?_\n",
    "\n",
    "    SVC (Support Vector Classification) é um classificador baseado na técnica de Support Vector Machines (SVM). Abaixo, alguns pontos-chave sobre o SVC:\n",
    "        •\tObjetivo:\n",
    "    O SVC busca encontrar o hiperplano que melhor separa as classes dos dados, maximizando a margem entre elas. Essa margem é a distância entre os pontos mais próximos de cada classe (os chamados support vectors).\n",
    "        •\tFuncionamento:\n",
    "        •\tUtiliza funções de kernel (como linear, polinomial, RBF, etc.) para transformar os dados em espaços de alta dimensão, facilitando a separação entre classes não linearmente separáveis.\n",
    "        •\tO modelo tenta minimizar o erro de classificação, enquanto maximiza a margem, resultando em um equilíbrio entre a complexidade do modelo e sua capacidade de generalização.\n",
    "        •\tAplicações:\n",
    "    É amplamente usado em tarefas de classificação, como reconhecimento de padrões, classificação de textos, imagens, entre outros, especialmente quando os dados possuem alta dimensionalidade.\n",
    "\n",
    "    Em resumo, o SVC é uma implementação prática das SVMs focada na classificação, oferecendo robustez e flexibilidade para lidar com diversos tipos de dados e desafios em problemas de classificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
